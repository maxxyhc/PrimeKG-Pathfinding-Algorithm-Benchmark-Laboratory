{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Repurposing Pathfinding Algorithm Benchmark\n",
    "\n",
    "**Purpose:** Evaluate graph pathfinding algorithms for drug repurposing by comparing predicted mechanistic pathways against curated ground truth pathways.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation visualization loaded\n",
      "  Use: generate_full_report(summary)\n",
      "  Or:  display_summary_table(summary)\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import heapq\n",
    "from typing import Dict, List, Tuple\n",
    "from collections import deque, Counter\n",
    "from evaluation_helpers import *\n",
    "from evaluation_metrics import *\n",
    "from Algorithms import *\n",
    "from evaluation_runner import run_evaluation\n",
    "import importlib\n",
    "import evaluation_visualization as ev\n",
    "importlib.reload(ev)\n",
    "from hyperparameter_tuning import (\n",
    "    run_full_grid_search,\n",
    "    plot_tuning_results,\n",
    "    get_best_predictions\n",
    ")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration complete. Paths set to:\n",
      "  nodes: /Users/johncollins/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/notebook/data/nodes.csv\n",
      "  edges: /Users/johncollins/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/notebook/data/edges.csv\n",
      "  ground_truth_nodes: /Users/johncollins/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/notebook/data/processed/benchmark_pathways_nodes.csv\n",
      "  ground_truth_edges: /Users/johncollins/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/notebook/data/processed/benchmark_pathways_edges.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === CONFIGURE PATHS ===\n",
    "# Update this to your project root directory\n",
    "# DATA_DIR = '/Users/maxchiu/Desktop/Primkg_github/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory'\n",
    "DATA_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "# File paths (relative to DATA_DIR)\n",
    "PATHS = {\n",
    "    'nodes': f'{DATA_DIR}/data/nodes.csv',\n",
    "    'edges': f'{DATA_DIR}/data/edges.csv',\n",
    "    'ground_truth_nodes': f'{DATA_DIR}/data/processed/benchmark_pathways_nodes.csv',\n",
    "    'ground_truth_edges': f'{DATA_DIR}/data/processed/benchmark_pathways_edges.csv'\n",
    "}\n",
    "\n",
    "print(\"Configuration complete. Paths set to:\")\n",
    "for name, path in PATHS.items():\n",
    "    print(f\"  {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data\n",
    "\n",
    "Load the PrimeKG knowledge graph and ground truth pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PrimeKG data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/johncollins/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/notebook/data/nodes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load PrimeKG data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading PrimeKG data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATHS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m edges \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(PATHS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m'\u001b[39m], encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Nodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(nodes)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/johncollins/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/notebook/data/nodes.csv'"
     ]
    }
   ],
   "source": [
    "# Load PrimeKG data\n",
    "print(\"Loading PrimeKG data...\")\n",
    "nodes = pd.read_csv(PATHS['nodes'], encoding=\"latin1\")\n",
    "edges = pd.read_csv(PATHS['edges'], encoding=\"latin1\")\n",
    "\n",
    "print(f\"  Nodes: {len(nodes):,}\")\n",
    "print(f\"  Edges: {len(edges):,}\")\n",
    "print(f\"  Node types: {nodes['node_type'].nunique()}\")\n",
    "print(f\"  Edge types: {edges['relation'].nunique()}\")\n",
    "\n",
    "# Load ground truth\n",
    "print(\"\\nLoading ground truth pathways...\")\n",
    "ground_truth_nodes = pd.read_csv(PATHS['ground_truth_nodes'], dtype={'node_index': int})\n",
    "ground_truth_edges = pd.read_csv(PATHS['ground_truth_edges'])\n",
    "\n",
    "pathways = ground_truth_nodes['pathway_id'].unique()\n",
    "print(f\"  Pathways: {len(pathways)}\")\n",
    "for p in pathways:\n",
    "    n_nodes = len(ground_truth_nodes[ground_truth_nodes['pathway_id'] == p])\n",
    "    print(f\"    - {p}: {n_nodes} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build Knowledge Graph\n",
    "\n",
    "Construct a NetworkX directed graph with node/edge attributes for pathfinding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(nodes_df, edges_df, bidirectional=True):\n",
    "    \"\"\"\n",
    "    Build a NetworkX graph from cleaned PrimeKG CSVs.\n",
    "    \n",
    "    nodes_df columns:\n",
    "        node_index, node_id, node_type, node_name, node_source\n",
    "        \n",
    "    edges_df columns:\n",
    "        relation, display_relation, x_index, y_index\n",
    "    \"\"\"\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # ---------- Add nodes ----------\n",
    "    for _, row in nodes_df.iterrows():\n",
    "        G.add_node(\n",
    "            int(row['node_index']),\n",
    "            node_id=str(row['node_id']),\n",
    "            node_name=str(row['node_name']),\n",
    "            node_type=str(row['node_type']),\n",
    "            node_source=str(row['node_source'])\n",
    "        )\n",
    "    \n",
    "    # ---------- Add edges ----------\n",
    "    for _, row in edges_df.iterrows():\n",
    "        G.add_edge(\n",
    "            int(row['x_index']),\n",
    "            int(row['y_index']),\n",
    "            relation=str(row['relation']),\n",
    "            display_relation=str(row['display_relation'])\n",
    "        )\n",
    "        \n",
    "        if bidirectional:\n",
    "            G.add_edge(\n",
    "                int(row['y_index']),\n",
    "                int(row['x_index']),\n",
    "                relation=str(row['relation']),\n",
    "                display_relation=str(row['display_relation'])\n",
    "            )\n",
    "    \n",
    "    return G\n",
    "\n",
    "print(\"Building graph...\")\n",
    "G = build_graph(nodes, edges, bidirectional=True)\n",
    "print(f\"Graph built: {G.number_of_nodes():,} nodes, {G.number_of_edges():,} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Algorithm 1 - Shortest Path Baseline\n",
    "\n",
    "The simplest baseline: find the shortest path (by hop count) between drug and disease.\n",
    "\n",
    "**Expected behavior:**\n",
    "- ✅ Will always find the target disease (if connected)\n",
    "- ❌ May take shortcuts through direct drug→disease edges\n",
    "- ❌ Ignores edge types and biological mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_shortest_path(graph, ground_truth_df):\n",
    "    \"\"\"\n",
    "    Run shortest path algorithm on all pathways.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions for each pathway\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        \n",
    "        # Get source (drug) and target (disease) indices\n",
    "        source_idx = int(pathway_df.iloc[0]['node_index'])\n",
    "        target_idx = int(pathway_df.iloc[-1]['node_index'])\n",
    "        \n",
    "        source_name = pathway_df.iloc[0]['node_name']\n",
    "        target_name = pathway_df.iloc[-1]['node_name']\n",
    "        \n",
    "        print(f\"\\n{pathway_id}: {source_name} → {target_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Find shortest path\n",
    "            predicted_path = nx.shortest_path(graph, source_idx, target_idx)\n",
    "            predicted_node_ids = [graph.nodes[idx]['node_id'] for idx in predicted_path]\n",
    "            predicted_node_names = [graph.nodes[idx]['node_name'] for idx in predicted_path]\n",
    "            \n",
    "            # Get edge relations along path\n",
    "            predicted_relations = []\n",
    "            for i in range(len(predicted_path) - 1):\n",
    "                edge_data = graph.get_edge_data(predicted_path[i], predicted_path[i+1])\n",
    "                predicted_relations.append(edge_data['relation'])\n",
    "            \n",
    "            print(f\"  ✓ Found path: {len(predicted_path)} nodes\")\n",
    "            print(f\"  Path: {' → '.join(predicted_node_names[:5])}{'...' if len(predicted_path) > 5 else ''}\")\n",
    "            \n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': ','.join(map(str, predicted_path)),\n",
    "                'predicted_node_ids': ','.join(predicted_node_ids),\n",
    "                'predicted_node_names': ','.join(predicted_node_names),\n",
    "                'predicted_relations': ','.join(predicted_relations),\n",
    "                'predicted_length': len(predicted_path),\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "            \n",
    "        except nx.NetworkXNoPath:\n",
    "            print(f\"  ✗ No path found\")\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': 'NONE',\n",
    "                'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE',\n",
    "                'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0,\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run shortest path\n",
    "print(\"=\"*60)\n",
    "print(\"Running Shortest Path Algorithm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sp_predictions = run_shortest_path(G, ground_truth_nodes)\n",
    "# sp_predictions.to_csv('baseline_shortest_path_predictions.csv', index=False)\n",
    "# print(\"\\n✓ Saved: baseline_shortest_path_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Meta-Path Constrained BFS\n",
    "\n",
    "An improved baseline that enforces biologically valid edge type sequences.\n",
    "\n",
    "**Valid meta-path patterns:**\n",
    "1. `drug → protein → disease` (direct mechanism)\n",
    "2. `drug → protein → protein → disease` (protein interactions)\n",
    "3. `drug → protein → anatomy → protein → disease` (tissue-specific)\n",
    "\n",
    "**Invalid shortcuts blocked:**\n",
    "- ❌ `drug → disease` (clinical indication, not mechanism)\n",
    "- ❌ `drug → drug → disease` (drug similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid meta-path patterns (edge type sequences)\n",
    "VALID_METAPATHS = [\n",
    "    # Pattern 1: Direct protein mechanism (drug → protein → disease)\n",
    "    ['drug_protein', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 2: Protein-protein interaction\n",
    "    ['drug_protein', 'protein_protein', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 3: Multiple protein interactions\n",
    "    ['drug_protein', 'protein_protein', 'protein_protein', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 4: Pathway-mediated\n",
    "    ['drug_protein', 'pathway_protein', 'disease_protein'],\n",
    "    ['drug_protein', 'pathway_protein', 'pathway_protein', 'disease_protein'],\n",
    "    ['drug_protein', 'pathway_protein', 'pathway_pathway', 'pathway_protein', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 5: Anatomy-mediated (tissue-specific)\n",
    "    ['drug_protein', 'anatomy_protein_present', 'anatomy_protein_present', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 6: Complex pathways\n",
    "    ['drug_protein', 'protein_protein', 'pathway_protein', 'disease_protein'],\n",
    "    ['drug_protein', 'pathway_protein', 'pathway_protein', 'pathway_protein', 'disease_protein'],\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(VALID_METAPATHS)} valid meta-path patterns:\")\n",
    "for i, pattern in enumerate(VALID_METAPATHS, 1):\n",
    "    print(f\"  {i}. {' → '.join(pattern)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_metapath(relations, valid_metapaths):\n",
    "    \"\"\"Check if a relation sequence matches any valid meta-path pattern.\"\"\"\n",
    "    return relations in valid_metapaths\n",
    "\n",
    "\n",
    "def could_match_metapath(relations, valid_metapaths):\n",
    "    \"\"\"Check if the current relation sequence could potentially lead to a valid path.\"\"\"\n",
    "    for pattern in valid_metapaths:\n",
    "        if len(relations) <= len(pattern):\n",
    "            if relations == pattern[:len(relations)]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def metapath_constrained_bfs(source_idx, target_idx, graph, valid_metapaths, max_length=10):\n",
    "    \"\"\"\n",
    "    Find shortest path that follows valid meta-path patterns.\n",
    "    \n",
    "    Uses BFS but only explores edges that could lead to a valid meta-path.\n",
    "    \n",
    "    Returns:\n",
    "        (path_nodes, path_relations) or ([], []) if no valid path found\n",
    "    \"\"\"\n",
    "    # Queue: (current_node, path_so_far, relations_so_far)\n",
    "    queue = deque([(source_idx, [source_idx], [])])\n",
    "    visited = {source_idx: []}  # Track visited states with relation sequences\n",
    "    \n",
    "    while queue:\n",
    "        current_node, path, relations = queue.popleft()\n",
    "        \n",
    "        # Check if we reached target with valid meta-path\n",
    "        if current_node == target_idx:\n",
    "            if is_valid_metapath(relations, valid_metapaths):\n",
    "                return path, relations\n",
    "        \n",
    "        # Stop if path too long\n",
    "        if len(path) >= max_length:\n",
    "            continue\n",
    "        \n",
    "        # Explore neighbors\n",
    "        for neighbor in graph.neighbors(current_node):\n",
    "            edge_data = graph.get_edge_data(current_node, neighbor)\n",
    "            new_relation = edge_data['relation']\n",
    "            new_relations = relations + [new_relation]\n",
    "            \n",
    "            # Only continue if this could lead to a valid meta-path\n",
    "            if could_match_metapath(new_relations, valid_metapaths):\n",
    "                state_key = (neighbor, tuple(new_relations))\n",
    "                \n",
    "                # Avoid revisiting same state\n",
    "                if neighbor not in visited or visited[neighbor] != new_relations:\n",
    "                    visited[neighbor] = new_relations\n",
    "                    queue.append((neighbor, path + [neighbor], new_relations))\n",
    "    \n",
    "    return [], []  # No valid path found\n",
    "\n",
    "\n",
    "def run_metapath_algorithm(graph, ground_truth_df, valid_metapaths):\n",
    "    \"\"\"\n",
    "    Run meta-path constrained BFS on all pathways.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        \n",
    "        source_idx = int(pathway_df.iloc[0]['node_index'])\n",
    "        target_idx = int(pathway_df.iloc[-1]['node_index'])\n",
    "        \n",
    "        source_name = pathway_df.iloc[0]['node_name']\n",
    "        target_name = pathway_df.iloc[-1]['node_name']\n",
    "        \n",
    "        gt_path = ' → '.join(pathway_df['node_name'].tolist())\n",
    "        \n",
    "        print(f\"\\n{pathway_id}: {source_name} → {target_name}\")\n",
    "        \n",
    "        # Find meta-path constrained path\n",
    "        predicted_path, predicted_relations = metapath_constrained_bfs(\n",
    "            source_idx, target_idx, graph, valid_metapaths\n",
    "        )\n",
    "        \n",
    "        if predicted_path:\n",
    "            predicted_node_ids = [graph.nodes[idx]['node_id'] for idx in predicted_path]\n",
    "            predicted_node_names = [graph.nodes[idx]['node_name'] for idx in predicted_path]\n",
    "            \n",
    "            print(f\"  ✓ Found valid path: {len(predicted_path)} nodes\")\n",
    "            print(f\"  Meta-path: {' → '.join(predicted_relations)}\")\n",
    "            print(f\"  Path: {' → '.join(predicted_node_names)}\")\n",
    "            print(f\"  Ground truth: {gt_path}\")\n",
    "            \n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': ','.join(map(str, predicted_path)),\n",
    "                'predicted_node_ids': ','.join(predicted_node_ids),\n",
    "                'predicted_node_names': ','.join(predicted_node_names),\n",
    "                'predicted_relations': ','.join(predicted_relations),\n",
    "                'predicted_length': len(predicted_path),\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  ✗ No valid meta-path found\")\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': 'NONE',\n",
    "                'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE',\n",
    "                'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0,\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run meta-path algorithm\n",
    "print(\"=\"*60)\n",
    "print(\"Running Meta-Path Constrained Algorithm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mp_predictions = run_metapath_algorithm(G, ground_truth_nodes, VALID_METAPATHS)\n",
    "# mp_predictions.to_csv('baseline_metapath_predictions.csv', index=False)\n",
    "# print(\"\\n✓ Saved: baseline_metapath_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 2: Hub-Penalized Weighted Shortest Path\n",
    "\n",
    "**Core Idea:** High-degree \"hub\" nodes (like inflammation markers) connect to everything but don't represent specific mechanisms. Penalize them.\n",
    "\n",
    "**Weight Formula:** `weight[u,v] = 1 + α * log(degree[v])`\n",
    "\n",
    "- α = 0.5 is a good default (can be tuned)\n",
    "- Higher degree → higher weight → less preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ALGORITHM 2: Hub-Penalized Weighted Shortest Path\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def run_hub_penalized(graph, ground_truth_df, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Run Hub-Penalized algorithm on all pathways.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Initialize algorithm\n",
    "    print(\"Initializing Hub-Penalized algorithm...\")\n",
    "    algo = HubPenalizedShortestPath(graph, alpha=alpha)\n",
    "    print(f\"  Edge weights computed (α={alpha})\")\n",
    "    \n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        \n",
    "        source_idx = int(pathway_df.iloc[0]['node_index'])\n",
    "        target_idx = int(pathway_df.iloc[-1]['node_index'])\n",
    "        source_name = pathway_df.iloc[0]['node_name']\n",
    "        target_name = pathway_df.iloc[-1]['node_name']\n",
    "        \n",
    "        print(f\"\\n{pathway_id}: {source_name} → {target_name}\")\n",
    "        \n",
    "        path, relations, weight = algo.find_path(source_idx, target_idx)\n",
    "        \n",
    "        if path:\n",
    "            node_ids = [graph.nodes[idx].get('node_id', str(idx)) for idx in path]\n",
    "            node_names = [graph.nodes[idx].get('node_name', str(idx)) for idx in path]\n",
    "            \n",
    "            print(f\"  ✓ Found path: {len(path)} nodes\")\n",
    "            print(f\"  Path: {' → '.join(node_names)}\")\n",
    "            \n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': ','.join(map(str, path)),\n",
    "                'predicted_node_ids': ','.join(node_ids),\n",
    "                'predicted_node_names': ','.join(node_names),\n",
    "                'predicted_relations': ','.join(relations),\n",
    "                'predicted_length': len(path),\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  ✗ No path found\")\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': 'NONE',\n",
    "                'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE',\n",
    "                'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0,\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run Algorithm 2\n",
    "print(\"=\"*60)\n",
    "print(\"Running Hub-Penalized Algorithm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "hub_predictions = run_hub_penalized(G, ground_truth_nodes, alpha=0.5)\n",
    "# hub_predictions.to_csv('hub_penalized_predictions.csv', index=False)\n",
    "# print(\"\\n✓ Saved: hub_penalized_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 3: PageRank-Inverse Weighted Shortest Path\n",
    "\n",
    "**Core Idea:** PageRank captures global graph centrality. Nodes with HIGH PageRank are generic hubs. We want paths through LOW PageRank (more specific) nodes.\n",
    "\n",
    "**Weight Formula:** `weight[u,v] = 1 / (1 + pagerank[v])`\n",
    "\n",
    "- Low PageRank → low weight → preferred\n",
    "- PageRank is computed once upfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ALGORITHM 3: PageRank-Inverse Weighted Shortest Path\n",
    "# ============================================================\n",
    "\n",
    "def run_pagerank_inverse(graph, ground_truth_df, damping=0.85):\n",
    "    \"\"\"\n",
    "    Run PageRank-Inverse algorithm on all pathways.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Initialize algorithm\n",
    "    print(\"Initializing PageRank-Inverse algorithm...\")\n",
    "    algo = PageRankInverseShortestPath(graph, damping=damping)\n",
    "    print(f\"  Edge weights computed\")\n",
    "    \n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        \n",
    "        source_idx = int(pathway_df.iloc[0]['node_index'])\n",
    "        target_idx = int(pathway_df.iloc[-1]['node_index'])\n",
    "        source_name = pathway_df.iloc[0]['node_name']\n",
    "        target_name = pathway_df.iloc[-1]['node_name']\n",
    "        \n",
    "        print(f\"\\n{pathway_id}: {source_name} → {target_name}\")\n",
    "        \n",
    "        path, relations, weight = algo.find_path(source_idx, target_idx)\n",
    "        \n",
    "        if path:\n",
    "            node_ids = [graph.nodes[idx].get('node_id', str(idx)) for idx in path]\n",
    "            node_names = [graph.nodes[idx].get('node_name', str(idx)) for idx in path]\n",
    "            \n",
    "            print(f\"  ✓ Found path: {len(path)} nodes\")\n",
    "            print(f\"  Path: {' → '.join(node_names)}\")\n",
    "            \n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': ','.join(map(str, path)),\n",
    "                'predicted_node_ids': ','.join(node_ids),\n",
    "                'predicted_node_names': ','.join(node_names),\n",
    "                'predicted_relations': ','.join(relations),\n",
    "                'predicted_length': len(path),\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  ✗ No path found\")\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': 'NONE',\n",
    "                'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE',\n",
    "                'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0,\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run Algorithm 3\n",
    "print(\"=\"*60)\n",
    "print(\"Running PageRank-Inverse Algorithm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pr_predictions = run_pagerank_inverse(G, ground_truth_nodes, damping=0.85)\n",
    "# pr_predictions.to_csv('pagerank_inverse_predictions.csv', index=False)\n",
    "# print(\"\\n✓ Saved: pagerank_inverse_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 4: Learned Embeddings + A* with Supervised Edge Weights\n",
    "\n",
    "**Core Idea:** Learn from known drug repurposing pathways what makes a \"good\" edge.\n",
    "\n",
    "**Two Phases:**\n",
    "1. **Embed:** Train Node2Vec (or use spectral embeddings) to capture graph structure\n",
    "2. **Learn:** Train MLP to predict edge goodness from:\n",
    "   - Embedding similarity\n",
    "   - Degree features\n",
    "   - Edge type\n",
    "\n",
    "**Search:** A* with learned weights + embedding-based heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ALGORITHM 4: Learned Embeddings + A* with Supervised Edge Weights\n",
    "# ============================================================\n",
    "\n",
    "def run_learned_astar(graph, ground_truth_df, embedding_dim=64):\n",
    "    \"\"\"\n",
    "    Run Learned Embeddings + A* algorithm on all pathways.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Initialize algorithm\n",
    "    print(\"Initializing Learned Embeddings + A* algorithm...\")\n",
    "    algo = LearnedEmbeddingsAStar(graph, embedding_dim=embedding_dim)\n",
    "    algo.train_embeddings()\n",
    "    \n",
    "    # Prepare training data from ground truth\n",
    "    training_pathways = []\n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        training_pathways.append({'path_nodes': pathway_df['node_index'].tolist()})\n",
    "    \n",
    "    algo.train_edge_weights(training_pathways)\n",
    "    \n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        \n",
    "        source_idx = int(pathway_df.iloc[0]['node_index'])\n",
    "        target_idx = int(pathway_df.iloc[-1]['node_index'])\n",
    "        source_name = pathway_df.iloc[0]['node_name']\n",
    "        target_name = pathway_df.iloc[-1]['node_name']\n",
    "        \n",
    "        print(f\"\\n{pathway_id}: {source_name} → {target_name}\")\n",
    "        \n",
    "        path, relations, weight = algo.find_path(source_idx, target_idx)\n",
    "        \n",
    "        if path:\n",
    "            node_ids = [graph.nodes[idx].get('node_id', str(idx)) for idx in path]\n",
    "            node_names = [graph.nodes[idx].get('node_name', str(idx)) for idx in path]\n",
    "            \n",
    "            print(f\"  ✓ Found path: {len(path)} nodes\")\n",
    "            print(f\"  Path: {' → '.join(node_names)}\")\n",
    "            \n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': ','.join(map(str, path)),\n",
    "                'predicted_node_ids': ','.join(node_ids),\n",
    "                'predicted_node_names': ','.join(node_names),\n",
    "                'predicted_relations': ','.join(relations),\n",
    "                'predicted_length': len(path),\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  ✗ No path found\")\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': 'NONE',\n",
    "                'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE',\n",
    "                'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0,\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run Algorithm 4\n",
    "print(\"=\"*60)\n",
    "print(\"Running Learned Embeddings + A* Algorithm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "learned_predictions = run_learned_astar(G, ground_truth_nodes, embedding_dim=64)\n",
    "# learned_predictions.to_csv('learned_astar_predictions.csv', index=False)\n",
    "# print(\"\\n✓ Saved: learned_astar_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 5: Semantic Bridging with Intermediate Node Scoring\n",
    "\n",
    "**Core Idea:** Use NLP to find paths where consecutive nodes are semantically related (they \"make sense\" together).\n",
    "\n",
    "**Weight Formula:** `weight[u,v] = 1 - β * cosine_sim(text_emb[u], text_emb[v])`\n",
    "\n",
    "- β = 0.3 balances semantic preference with path length\n",
    "- Uses TF-IDF embeddings (or SciBERT if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ALGORITHM 5: Semantic Bridging with Intermediate Node Scoring\n",
    "# ============================================================\n",
    "\n",
    "def run_semantic_bridging(graph, ground_truth_df, beta=0.3):\n",
    "    \"\"\"\n",
    "    Run Semantic Bridging algorithm on all pathways.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Initialize algorithm\n",
    "    print(\"Initializing Semantic Bridging algorithm...\")\n",
    "    algo = SemanticBridgingPath(graph, beta=beta)\n",
    "    algo.compute_embeddings()\n",
    "    algo.compute_edge_weights()\n",
    "    \n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        \n",
    "        source_idx = int(pathway_df.iloc[0]['node_index'])\n",
    "        target_idx = int(pathway_df.iloc[-1]['node_index'])\n",
    "        source_name = pathway_df.iloc[0]['node_name']\n",
    "        target_name = pathway_df.iloc[-1]['node_name']\n",
    "        \n",
    "        print(f\"\\n{pathway_id}: {source_name} → {target_name}\")\n",
    "        \n",
    "        path, relations, weight = algo.find_path(source_idx, target_idx)\n",
    "        \n",
    "        if path:\n",
    "            node_ids = [graph.nodes[idx].get('node_id', str(idx)) for idx in path]\n",
    "            node_names = [graph.nodes[idx].get('node_name', str(idx)) for idx in path]\n",
    "            \n",
    "            print(f\"  ✓ Found path: {len(path)} nodes\")\n",
    "            print(f\"  Path: {' → '.join(node_names)}\")\n",
    "            \n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': ','.join(map(str, path)),\n",
    "                'predicted_node_ids': ','.join(node_ids),\n",
    "                'predicted_node_names': ','.join(node_names),\n",
    "                'predicted_relations': ','.join(relations),\n",
    "                'predicted_length': len(path),\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  ✗ No path found\")\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': 'NONE',\n",
    "                'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE',\n",
    "                'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0,\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run Algorithm 5\n",
    "print(\"=\"*60)\n",
    "print(\"Running Semantic Bridging Algorithm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "semantic_predictions = run_semantic_bridging(G, ground_truth_nodes, beta=0.3)\n",
    "# semantic_predictions.to_csv('semantic_bridging_predictions.csv', index=False)\n",
    "# print(\"\\n✓ Saved: semantic_bridging_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate Algorithms\n",
    "\n",
    "Calculate all 9 metrics for both algorithms and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {\n",
    "    'Dijkstra': sp_predictions,\n",
    "    'Meta-Path': mp_predictions,\n",
    "    'Hub-Penalized': hub_predictions,\n",
    "    'PageRank-Inverse': pr_predictions,\n",
    "    'Semantic-Bridging': semantic_predictions,\n",
    "}\n",
    "\n",
    "print(edges.columns.tolist())\n",
    "\n",
    "results, summary = run_evaluation(\n",
    "    predictions_dict=predictions_dict,\n",
    "    ground_truth_nodes=ground_truth_nodes,\n",
    "    ground_truth_edges=ground_truth_edges,\n",
    "    edges_df=edges\n",
    ")\n",
    "\n",
    "# 用新的 visualization\n",
    "ev.display_summary_table(summary)\n",
    "\n",
    "\n",
    "# results.to_csv('evaluation_results.csv', index=False)\n",
    "# summary.to_csv('evaluation_summary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run grid search for all tunable algorithms\n",
    "# best_configs, tuning_results = run_full_grid_search(\n",
    "#     G,                          # Your NetworkX graph\n",
    "#     ground_truth_nodes,         # Ground truth nodes DataFrame\n",
    "#     ground_truth_edges,         # Ground truth edges DataFrame\n",
    "#     edges,                      # PrimeKG edges DataFrame\n",
    "#     hub_alphas=[0.1, 0.3, 0.5, 0.7, 1.0, 1.5],   # Alpha values to test for Hub-Penalized\n",
    "#     pr_dampings=[0.7, 0.85, 0.9],                 # Damping values to test for PageRank\n",
    "#     semantic_betas=[0.1, 0.3, 0.5, 0.7]          # Beta values to test for Semantic-Bridging\n",
    "# )\n",
    "\n",
    "\n",
    "# # Generate predictions using the optimal parameters found\n",
    "# best_predictions = get_best_predictions(G, ground_truth_nodes, best_configs)\n",
    "\n",
    "# # Combine with non-tunable algorithms (Dijkstra, Meta-Path)\n",
    "# predictions_dict = {\n",
    "#     'Dijkstra': sp_predictions,\n",
    "#     'Meta-Path': mp_predictions,\n",
    "#     **best_predictions  # Adds tuned Hub-Penalized, PageRank-Inverse, Semantic-Bridging\n",
    "# }\n",
    "\n",
    "# # Run final evaluation with all algorithms\n",
    "# results, summary = run_evaluation(\n",
    "#     predictions_dict=predictions_dict,\n",
    "#     ground_truth_nodes=ground_truth_nodes,\n",
    "#     ground_truth_edges=ground_truth_edges,\n",
    "#     edges_df=edges\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results Summary\n",
    "\n",
    "Compare algorithm performance across all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics per algorithm\n",
    "metrics = ['precision', 'recall', 'f1_score', 'hits_at_1', 'relation_type_accuracy', \n",
    "           'hub_node_ratio', 'path_edit_distance', 'path_length_mae']\n",
    "\n",
    "summary = all_eval.groupby('algorithm')[metrics].mean().round(3)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ALGORITHM COMPARISON: Average Metrics Across All Pathways\")\n",
    "print(\"=\"*70\n",
    "print(summary.T.to_string())\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Count perfect matches\n",
    "print(\"\\nPerfect Matches (Edit Distance = 0):\")\n",
    "for alg in ['Shortest Path', 'Meta-Path']:\n",
    "    perfect = (all_eval[all_eval['algorithm'] == alg]['path_edit_distance'] == 0).sum()\n",
    "    total = len(all_eval[all_eval['algorithm'] == alg])\n",
    "    print(f\"  {alg}: {perfect}/{total} pathways\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
