{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Tuning: Learned A* (v2) & Semantic Bridging (v2)\n",
    "\n",
    "**Purpose:** Improve Algorithms 4 and 5 from the baseline benchmark with:\n",
    "- **Meta-path awareness** — mine valid edge-type patterns from ground truth, use as soft/hard constraints\n",
    "- **Path-level context** (A*) — edge features include hop count, distance to target, node types\n",
    "- **Node-type-aware features** (A*) — replace spectral embeddings with biologically meaningful features\n",
    "- **5-fold cross-validation** (A*) — eliminate train-on-test leakage using pre-assigned folds\n",
    "- **Per-edge-type weighting** (Semantic) — learned penalties from GT edge-type frequency\n",
    "- **Soft meta-path penalties** (Semantic) — 10x weight multiplier for edges inconsistent with valid patterns\n",
    "\n",
    "**Data requirement:** PrimeKG `nodes.csv` and `edges.csv` in `data/raw/`. Ground truth and fold assignments in `data/processed/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from typing import Dict, List, Tuple, Set\n",
    "from collections import Counter\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✓ Imports loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  ✓  nodes: ../data/raw/nodes.csv\n",
      "  ✓  edges: ../data/raw/edges.csv\n",
      "  ✓  ground_truth_nodes: ../data/processed/benchmark_pathways_nodes.csv\n",
      "  ✓  ground_truth_edges: ../data/processed/benchmark_pathways_edges.csv\n",
      "  ✓  fold_assignments: ../data/processed/pathway_fold_assignments.csv\n",
      "  min_pathway_nodes: 4\n",
      "  n_folds: 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = '..'\n",
    "\n",
    "PATHS = {\n",
    "    'nodes':              f'{DATA_DIR}/data/raw/nodes.csv',\n",
    "    'edges':              f'{DATA_DIR}/data/raw/edges.csv',\n",
    "    'ground_truth_nodes': f'{DATA_DIR}/data/processed/benchmark_pathways_nodes.csv',\n",
    "    'ground_truth_edges': f'{DATA_DIR}/data/processed/benchmark_pathways_edges.csv',\n",
    "    'fold_assignments':   f'{DATA_DIR}/data/processed/pathway_fold_assignments.csv',\n",
    "}\n",
    "\n",
    "MIN_PATHWAY_NODES = 4\n",
    "N_FOLDS = 5\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for name, path in PATHS.items():\n",
    "    exists = \"✓\" if os.path.exists(path) else \"✗ NOT FOUND\"\n",
    "    print(f\"  {exists}  {name}: {path}\")\n",
    "print(f\"  min_pathway_nodes: {MIN_PATHWAY_NODES}\")\n",
    "print(f\"  n_folds: {N_FOLDS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation Helpers & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation helpers & metrics loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EVALUATION HELPERS & METRICS (all inline)\n",
    "# ============================================================\n",
    "\n",
    "def is_valid_prediction(predicted_ids):\n",
    "    return predicted_ids and predicted_ids != ['NONE']\n",
    "\n",
    "def calculate_edit_distance(predicted_ids, ground_truth_ids):\n",
    "    if not predicted_ids or predicted_ids == ['NONE']:\n",
    "        return 1.0\n",
    "    m, n = len(predicted_ids), len(ground_truth_ids)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if predicted_ids[i - 1] == ground_truth_ids[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
    "    return dp[m][n] / max(m, n)\n",
    "\n",
    "def compute_degree_counts(edges_df):\n",
    "    degree_count = Counter()\n",
    "    for _, row in edges_df.iterrows():\n",
    "        degree_count[row['x_index']] += 1\n",
    "        degree_count[row['y_index']] += 1\n",
    "    return degree_count\n",
    "\n",
    "def compute_hub_threshold(degree_count, percentile=95):\n",
    "    return np.percentile(list(degree_count.values()), percentile)\n",
    "\n",
    "def calculate_hits_at_k(predicted_ids, ground_truth_target, k_values=[1, 3, 5]):\n",
    "    hits = {f'hits_at_{k}': 0 for k in k_values}\n",
    "    if not is_valid_prediction(predicted_ids):\n",
    "        return hits\n",
    "    for k in k_values:\n",
    "        last_k = predicted_ids[-k:] if len(predicted_ids) >= k else predicted_ids\n",
    "        hits[f'hits_at_{k}'] = 1 if ground_truth_target in last_k else 0\n",
    "    return hits\n",
    "\n",
    "def calculate_relation_accuracy(predicted_relations, ground_truth_edge_types):\n",
    "    if not predicted_relations:\n",
    "        return 0.0\n",
    "    gt_types = set(ground_truth_edge_types)\n",
    "    return sum(1 for r in predicted_relations if r in gt_types) / len(predicted_relations)\n",
    "\n",
    "def calculate_path_length_mae(predicted_length, ground_truth_length):\n",
    "    return abs(predicted_length - ground_truth_length)\n",
    "\n",
    "def calculate_hub_node_ratio(predicted_indices, degree_count, hub_threshold):\n",
    "    if not predicted_indices:\n",
    "        return 0.0\n",
    "    return sum(1 for idx in predicted_indices if degree_count.get(idx, 0) >= hub_threshold) / len(predicted_indices)\n",
    "\n",
    "def metric_precision(predicted_ids, ground_truth_ids):\n",
    "    if not is_valid_prediction(predicted_ids):\n",
    "        return 0.0\n",
    "    pred_set, gt_set = set(predicted_ids), set(ground_truth_ids)\n",
    "    return len(pred_set & gt_set) / len(pred_set)\n",
    "\n",
    "def metric_recall(predicted_ids, ground_truth_ids):\n",
    "    if not is_valid_prediction(predicted_ids):\n",
    "        return 0.0\n",
    "    pred_set, gt_set = set(predicted_ids), set(ground_truth_ids)\n",
    "    return len(pred_set & gt_set) / len(gt_set) if gt_set else 0.0\n",
    "\n",
    "def metric_f1(predicted_ids, ground_truth_ids):\n",
    "    p = metric_precision(predicted_ids, ground_truth_ids)\n",
    "    r = metric_recall(predicted_ids, ground_truth_ids)\n",
    "    return 2 * p * r / (p + r) if (p + r) > 0 else 0.0\n",
    "\n",
    "def metric_path_length_accuracy(predicted_length, ground_truth_length):\n",
    "    if predicted_length == 0 and ground_truth_length == 0:\n",
    "        return 1.0\n",
    "    max_len = max(predicted_length, ground_truth_length)\n",
    "    return 1 - abs(predicted_length - ground_truth_length) / max_len if max_len > 0 else 0.0\n",
    "\n",
    "def metric_mrr(predicted_ids, ground_truth_ids):\n",
    "    if not is_valid_prediction(predicted_ids):\n",
    "        return 0.0\n",
    "    gt_set = set(ground_truth_ids)\n",
    "    for rank, node in enumerate(predicted_ids, start=1):\n",
    "        if node in gt_set:\n",
    "            return 1 / rank\n",
    "    return 0.0\n",
    "\n",
    "print(\"✓ Evaluation helpers & metrics loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Shared Pathfinding Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Shared engine loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TRANSITION FILTER & DIJKSTRA ENGINE\n",
    "# ============================================================\n",
    "\n",
    "def allowed_transition(G, src, u, v) -> bool:\n",
    "    u_type = G.nodes[u].get(\"node_type\", \"\")\n",
    "    v_type = G.nodes[v].get(\"node_type\", \"\")\n",
    "    if u_type == \"drug\" and v_type == \"disease\":\n",
    "        return False\n",
    "    src_type = G.nodes[src].get(\"node_type\", \"\")\n",
    "    if src_type == \"drug\" and u == src and v_type == \"drug\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def find_path_engine(graph, weighted_graph, source, target, transition_fn):\n",
    "    dist = {source: 0.0}\n",
    "    parent = {source: None}\n",
    "    pq = [(0.0, source)]\n",
    "    while pq:\n",
    "        cur_cost, u = heapq.heappop(pq)\n",
    "        if cur_cost != dist.get(u, float('inf')):\n",
    "            continue\n",
    "        if u == target:\n",
    "            break\n",
    "        for v in graph.successors(u):\n",
    "            if not transition_fn(graph, source, u, v):\n",
    "                continue\n",
    "            w = weighted_graph[u][v].get(\"weight\", 1.0)\n",
    "            new_cost = cur_cost + w\n",
    "            if new_cost < dist.get(v, float('inf')):\n",
    "                dist[v] = new_cost\n",
    "                parent[v] = u\n",
    "                heapq.heappush(pq, (new_cost, v))\n",
    "    if target not in dist:\n",
    "        return [], [], float(\"inf\")\n",
    "    path = []\n",
    "    cur = target\n",
    "    while cur is not None:\n",
    "        path.append(cur)\n",
    "        cur = parent[cur]\n",
    "    path.reverse()\n",
    "    relations = []\n",
    "    for i in range(len(path) - 1):\n",
    "        edge_data = graph.get_edge_data(path[i], path[i + 1]) or {}\n",
    "        relations.append(edge_data.get(\"relation\", \"unknown\"))\n",
    "    return path, relations, dist[target]\n",
    "\n",
    "\n",
    "print(\"✓ Shared engine loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Meta-Path Mining\n",
    "\n",
    "Extract the dominant edge-type patterns from ground truth pathways. These become constraints for both v2 algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Meta-path mining functions loaded\n"
     ]
    }
   ],
   "source": [
    "def mine_metapath_patterns(gt_edges_df, gt_nodes_df, min_count=2):\n",
    "    \"\"\"\n",
    "    Extract meta-path patterns (edge-type sequences) from ground truth pathways.\n",
    "\n",
    "    Returns:\n",
    "        patterns     : list of tuples, e.g. [('drug_protein', 'disease_protein'), ...]\n",
    "        pattern_counts: Counter of pattern frequencies\n",
    "        prefix_set   : set of all valid prefixes (for constraining search)\n",
    "    \"\"\"\n",
    "    # Auto-detect edge type column\n",
    "    edge_type_col = None\n",
    "    for candidate in ['relation_type', 'relation', 'edge_type']:\n",
    "        if candidate in gt_edges_df.columns:\n",
    "            edge_type_col = candidate\n",
    "            break\n",
    "    if edge_type_col is None:\n",
    "        edge_type_col = gt_edges_df.columns[0]\n",
    "    print(f\"  Using edge type column: '{edge_type_col}'\")\n",
    "\n",
    "    pattern_counts = Counter()\n",
    "\n",
    "    for pathway_id in gt_edges_df['pathway_id'].unique():\n",
    "        pw_edges = gt_edges_df[gt_edges_df['pathway_id'] == pathway_id]\n",
    "\n",
    "        # Sort edges by step_from to get the correct sequence\n",
    "        if 'step_from' in pw_edges.columns:\n",
    "            pw_edges = pw_edges.sort_values('step_from')\n",
    "\n",
    "        edge_types = tuple(pw_edges[edge_type_col].tolist())\n",
    "        if len(edge_types) > 0:\n",
    "            pattern_counts[edge_types] += 1\n",
    "\n",
    "    # Filter to patterns seen at least min_count times\n",
    "    patterns = [p for p, c in pattern_counts.most_common() if c >= min_count]\n",
    "\n",
    "    # Build prefix set for search-time constraint checking\n",
    "    prefix_set = set()\n",
    "    for pattern in patterns:\n",
    "        for i in range(1, len(pattern) + 1):\n",
    "            prefix_set.add(pattern[:i])\n",
    "\n",
    "    # Also include ALL patterns (even rare) in prefix set for flexibility\n",
    "    for pattern in pattern_counts:\n",
    "        for i in range(1, len(pattern) + 1):\n",
    "            prefix_set.add(pattern[:i])\n",
    "\n",
    "    print(f\"  Mined {len(pattern_counts)} unique meta-path patterns\")\n",
    "    print(f\"  {len(patterns)} patterns with count >= {min_count}\")\n",
    "    print(f\"  {len(prefix_set)} valid prefixes for search constraint\")\n",
    "    print(f\"\\n  Top 15 patterns:\")\n",
    "    for pattern, count in pattern_counts.most_common(15):\n",
    "        print(f\"    {count:3d}x  {' → '.join(pattern)}\")\n",
    "\n",
    "    return patterns, pattern_counts, prefix_set\n",
    "\n",
    "\n",
    "def compute_edge_type_weights(gt_edges_df, all_edge_types, bonus=0.3, penalty=2.0):\n",
    "    \"\"\"\n",
    "    Compute per-edge-type weight multipliers from ground truth frequency.\n",
    "\n",
    "    Frequent GT edge types get a bonus (multiplier < 1).\n",
    "    Rare/absent edge types get a penalty (multiplier > 1).\n",
    "    \"\"\"\n",
    "    edge_type_col = None\n",
    "    for candidate in ['relation_type', 'relation', 'edge_type']:\n",
    "        if candidate in gt_edges_df.columns:\n",
    "            edge_type_col = candidate\n",
    "            break\n",
    "    if edge_type_col is None:\n",
    "        edge_type_col = gt_edges_df.columns[0]\n",
    "\n",
    "    gt_counts = Counter(gt_edges_df[edge_type_col].tolist())\n",
    "    total = sum(gt_counts.values())\n",
    "\n",
    "    weights = {}\n",
    "    for edge_type in all_edge_types:\n",
    "        freq = gt_counts.get(edge_type, 0) / total if total > 0 else 0\n",
    "        if freq > 0.05:\n",
    "            weights[edge_type] = 1.0 - bonus * min(freq * 5, 1.0)  # reward: 0.7–1.0\n",
    "        elif freq > 0:\n",
    "            weights[edge_type] = 1.0  # neutral\n",
    "        else:\n",
    "            weights[edge_type] = penalty  # penalize unseen types\n",
    "    \n",
    "    print(f\"  Edge type weights (sample):\")\n",
    "    for et, w in sorted(weights.items(), key=lambda x: x[1])[:10]:\n",
    "        print(f\"    {et:<35s}: {w:.3f}\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "print(\"✓ Meta-path mining functions loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Algorithm 4 v2: Improved Learned A*\n",
    "\n",
    "**Changes from v1:**\n",
    "- Edge features now include **path-level context**: hop count, node types (one-hot), distance to target\n",
    "- **Meta-path prefix constraint**: A* only expands edges consistent with valid GT patterns\n",
    "- **Per-edge-type weight multiplier**: learned from GT frequency\n",
    "- **5-fold CV built in**: `train_and_evaluate_cv()` trains on 4 folds, tests on 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LearnedAStarV2 loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ALGORITHM 4 v2: Learned A* with Path Context + Meta-Path Constraints\n",
    "# ============================================================\n",
    "\n",
    "# Node type vocabulary for one-hot encoding\n",
    "NODE_TYPES = ['drug', 'gene/protein', 'disease', 'biological_process',\n",
    "              'molecular_function', 'pathway', 'anatomy', 'effect/phenotype',\n",
    "              'cellular_component', 'exposure']\n",
    "\n",
    "NODE_TYPE_TO_IDX = {t: i for i, t in enumerate(NODE_TYPES)}\n",
    "\n",
    "\n",
    "class LearnedAStarV2:\n",
    "    def __init__(self, graph: nx.DiGraph, embedding_dim: int = 64,\n",
    "                 prefix_set: Set[tuple] = None, edge_type_weights: Dict[str, float] = None):\n",
    "        self.graph = graph\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = None\n",
    "        self.edge_weights = None\n",
    "        self.scaler = None\n",
    "        self.mlp = None\n",
    "        self.degrees = dict(graph.degree())\n",
    "        self.prefix_set = prefix_set or set()\n",
    "        self.edge_type_weights = edge_type_weights or {}\n",
    "\n",
    "    def _node_type_onehot(self, node: int) -> np.ndarray:\n",
    "        \"\"\"One-hot encode node type.\"\"\"\n",
    "        vec = np.zeros(len(NODE_TYPES))\n",
    "        ntype = self.graph.nodes[node].get('node_type', '')\n",
    "        idx = NODE_TYPE_TO_IDX.get(ntype, -1)\n",
    "        if idx >= 0:\n",
    "            vec[idx] = 1.0\n",
    "        return vec\n",
    "\n",
    "    def train_embeddings(self) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"Compute spectral embeddings.\"\"\"\n",
    "        print(\"  Computing spectral embeddings...\")\n",
    "        G_undirected = self.graph.to_undirected()\n",
    "        largest_cc = max(nx.connected_components(G_undirected), key=len)\n",
    "        G_sub = G_undirected.subgraph(largest_cc)\n",
    "        L = nx.normalized_laplacian_matrix(G_sub)\n",
    "        k = min(self.embedding_dim + 1, L.shape[0] - 2)\n",
    "        eigenvalues, eigenvectors = eigsh(L, k=k, which='SM')\n",
    "        node_list = list(G_sub.nodes())\n",
    "        self.embeddings = {}\n",
    "        for i, node in enumerate(node_list):\n",
    "            self.embeddings[node] = eigenvectors[i, 1:]\n",
    "        for node in self.graph.nodes():\n",
    "            if node not in self.embeddings:\n",
    "                self.embeddings[node] = np.random.randn(k - 1) * 0.01\n",
    "        print(f\"  Embeddings: {len(self.embeddings):,} nodes, dim={k-1}\")\n",
    "        return self.embeddings\n",
    "\n",
    "    def _edge_features_v2(self, u: int, v: int, hop_count: int = 0,\n",
    "                          source: int = None, target: int = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        V2 edge features: original features + path context + node types.\n",
    "        \"\"\"\n",
    "        features = []\n",
    "\n",
    "        # --- Original features ---\n",
    "        if self.embeddings:\n",
    "            emb_u = self.embeddings.get(u, np.zeros(self.embedding_dim))\n",
    "            emb_v = self.embeddings.get(v, np.zeros(self.embedding_dim))\n",
    "            norm_u, norm_v = np.linalg.norm(emb_u), np.linalg.norm(emb_v)\n",
    "            cos_sim = np.dot(emb_u, emb_v) / (norm_u * norm_v) if norm_u > 0 and norm_v > 0 else 0.0\n",
    "            features.append(cos_sim)\n",
    "            features.append(np.linalg.norm(emb_u - emb_v))\n",
    "\n",
    "        features.append(np.log1p(self.degrees.get(u, 0)))\n",
    "        features.append(np.log1p(self.degrees.get(v, 0)))\n",
    "        features.append(np.log1p(self.degrees.get(u, 1) / max(self.degrees.get(v, 1), 1)))\n",
    "\n",
    "        # --- NEW: Path-level context ---\n",
    "        features.append(float(hop_count))\n",
    "\n",
    "        # Distance from v to target (embedding space)\n",
    "        if self.embeddings and target is not None:\n",
    "            emb_v = self.embeddings.get(v, np.zeros(self.embedding_dim))\n",
    "            emb_t = self.embeddings.get(target, np.zeros(self.embedding_dim))\n",
    "            features.append(np.linalg.norm(emb_v - emb_t))\n",
    "        else:\n",
    "            features.append(0.0)\n",
    "\n",
    "        # --- NEW: Node type one-hots for u and v ---\n",
    "        features.extend(self._node_type_onehot(u))\n",
    "        features.extend(self._node_type_onehot(v))\n",
    "\n",
    "        # --- NEW: Edge type one-hot ---\n",
    "        edge_data = self.graph.get_edge_data(u, v) or {}\n",
    "        edge_rel = edge_data.get('relation', 'unknown')\n",
    "        # Use a compact encoding: hash to fixed-size vector\n",
    "        edge_type_feat = np.zeros(8)\n",
    "        edge_type_feat[hash(edge_rel) % 8] = 1.0\n",
    "        features.extend(edge_type_feat)\n",
    "\n",
    "        return np.array(features)\n",
    "\n",
    "    def train_edge_weights(self, training_pathways: List[Dict], negative_ratio: float = 3.0):\n",
    "        \"\"\"Train MLP on v2 features with path context.\"\"\"\n",
    "        if self.embeddings is None:\n",
    "            self.train_embeddings()\n",
    "        print(\"  Training edge weight MLP (v2 features)...\")\n",
    "\n",
    "        X_train, y_train = [], []\n",
    "        positive_edges = set()\n",
    "\n",
    "        for pathway in training_pathways:\n",
    "            path = pathway['path_nodes']\n",
    "            source, target = path[0], path[-1]\n",
    "            for hop_i in range(len(path) - 1):\n",
    "                u, v = path[hop_i], path[hop_i + 1]\n",
    "                if self.graph.has_edge(u, v):\n",
    "                    positive_edges.add((u, v))\n",
    "                    X_train.append(self._edge_features_v2(u, v, hop_count=hop_i,\n",
    "                                                          source=source, target=target))\n",
    "                    y_train.append(0.1)\n",
    "\n",
    "        all_edges = list(self.graph.edges())\n",
    "        np.random.shuffle(all_edges)\n",
    "        n_negative = int(len(positive_edges) * negative_ratio)\n",
    "        neg_count = 0\n",
    "        for u, v in all_edges:\n",
    "            if neg_count >= n_negative:\n",
    "                break\n",
    "            if (u, v) not in positive_edges:\n",
    "                X_train.append(self._edge_features_v2(u, v, hop_count=2))\n",
    "                y_train.append(1.0)\n",
    "                neg_count += 1\n",
    "\n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_train)\n",
    "\n",
    "        self.mlp = MLPRegressor(hidden_layer_sizes=(64, 32), activation='relu',\n",
    "                                max_iter=500, early_stopping=True, random_state=42)\n",
    "        self.mlp.fit(X_scaled, y_train)\n",
    "        print(f\"  MLP trained on {len(X_train)} samples (R²={self.mlp.score(X_scaled, y_train):.3f})\")\n",
    "        print(f\"  Feature dim: {X_train.shape[1]}\")\n",
    "\n",
    "    def _heuristic(self, node: int, target: int) -> float:\n",
    "        if self.embeddings is None:\n",
    "            return 0.0\n",
    "        emb_n = self.embeddings.get(node, np.zeros(self.embedding_dim))\n",
    "        emb_t = self.embeddings.get(target, np.zeros(self.embedding_dim))\n",
    "        return np.linalg.norm(emb_n - emb_t) * 0.1\n",
    "\n",
    "    def _is_valid_prefix(self, relation_seq: tuple) -> bool:\n",
    "        \"\"\"Check if the current edge-type sequence is a prefix of any known GT pattern.\"\"\"\n",
    "        if not self.prefix_set:\n",
    "            return True  # no constraints\n",
    "        return relation_seq in self.prefix_set\n",
    "\n",
    "    def find_path(self, source: int, target: int) -> Tuple[List[int], List[str], float]:\n",
    "            \"\"\"A* with learned edge weights and edge-type multipliers. No relation tracking in state.\"\"\"\n",
    "            counter = 0\n",
    "            open_set = [(self._heuristic(source, target), counter, source, [source], 0.0)]\n",
    "            visited = set()\n",
    "\n",
    "            while open_set:\n",
    "                f_score, _, current, path, g_score = heapq.heappop(open_set)\n",
    "\n",
    "                if current == target:\n",
    "                    relations = []\n",
    "                    for i in range(len(path) - 1):\n",
    "                        edge_data = self.graph.get_edge_data(path[i], path[i + 1])\n",
    "                        relations.append(edge_data.get('relation', 'unknown'))\n",
    "                    return path, relations, g_score\n",
    "\n",
    "                if current in visited:\n",
    "                    continue\n",
    "                visited.add(current)\n",
    "\n",
    "                hop_count = len(path) - 1\n",
    "\n",
    "                for neighbor in self.graph.neighbors(current):\n",
    "                    if neighbor in visited:\n",
    "                        continue\n",
    "                    if not allowed_transition(self.graph, source, current, neighbor):\n",
    "                        continue\n",
    "\n",
    "                    # MLP-predicted base weight\n",
    "                    if self.mlp is not None and self.scaler is not None:\n",
    "                        feat = self._edge_features_v2(current, neighbor, hop_count=hop_count,\n",
    "                                                    source=source, target=target)\n",
    "                        feat_scaled = self.scaler.transform(feat.reshape(1, -1))\n",
    "                        base_weight = float(np.clip(self.mlp.predict(feat_scaled)[0], 0.01, 2.0))\n",
    "                    else:\n",
    "                        base_weight = 1.0\n",
    "\n",
    "                    # Edge-type multiplier (baked-in meta-path awareness)\n",
    "                    edge_data = self.graph.get_edge_data(current, neighbor) or {}\n",
    "                    edge_rel = edge_data.get('relation', 'unknown')\n",
    "                    type_mult = self.edge_type_weights.get(edge_rel, 1.5)\n",
    "\n",
    "                    edge_weight = base_weight * type_mult\n",
    "                    new_g = g_score + edge_weight\n",
    "                    new_f = new_g + self._heuristic(neighbor, target)\n",
    "                    counter += 1\n",
    "                    heapq.heappush(open_set, (new_f, counter, neighbor, path + [neighbor], new_g))\n",
    "\n",
    "            return [], [], float('inf')\n",
    "\n",
    "\n",
    "print(\"✓ LearnedAStarV2 loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Algorithm 5 v2: Improved Semantic Bridging\n",
    "\n",
    "**Changes from v1:**\n",
    "- **Per-edge-type weight multipliers** learned from GT frequency (penalize `drug_effect`, reward `drug_protein`)\n",
    "- **Soft meta-path penalty**: edges inconsistent with any valid GT prefix get 10x weight\n",
    "- **Graph co-occurrence features**: neighbor overlap (Jaccard) supplements TF-IDF for gene symbols\n",
    "- **Separate β by node-type pair**: different similarity discounts for drug→protein vs process→disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SemanticBridgingV2 loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ALGORITHM 5 v2: Semantic Bridging with Edge-Type Weights + Meta-Path Penalties\n",
    "# ============================================================\n",
    "\n",
    "class SemanticBridgingV2:\n",
    "    def __init__(self, graph: nx.DiGraph, beta: float = 0.3,\n",
    "                 prefix_set: Set[tuple] = None,\n",
    "                 edge_type_weights: Dict[str, float] = None,\n",
    "                 metapath_penalty: float = 10.0):\n",
    "        self.graph = graph\n",
    "        self.beta = beta\n",
    "        self.embeddings = None\n",
    "        self.weighted_graph = None\n",
    "        self.prefix_set = prefix_set or set()\n",
    "        self.edge_type_weights = edge_type_weights or {}\n",
    "        self.metapath_penalty = metapath_penalty\n",
    "        self.descriptions = {n: graph.nodes[n].get('node_name', str(n)) for n in graph.nodes()}\n",
    "        self.neighbor_cache = {}\n",
    "\n",
    "    def compute_embeddings(self) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"TF-IDF + SVD embeddings, supplemented with neighbor-overlap features.\"\"\"\n",
    "        print(\"  Computing TF-IDF embeddings...\")\n",
    "        nodes = list(self.graph.nodes())\n",
    "        texts = [self.descriptions[n] for n in nodes]\n",
    "\n",
    "        vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "        tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "        n_components = min(64, tfidf_matrix.shape[1] - 1)\n",
    "        svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "        tfidf_emb = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "        print(\"  Building neighbor cache for co-occurrence features...\")\n",
    "        for node in nodes:\n",
    "            self.neighbor_cache[node] = set(self.graph.neighbors(node))\n",
    "\n",
    "        self.embeddings = {node: tfidf_emb[i] for i, node in enumerate(nodes)}\n",
    "        self.tfidf_dim = n_components\n",
    "        print(f\"  Embeddings: {len(self.embeddings):,} nodes, dim={n_components}\")\n",
    "        return self.embeddings\n",
    "\n",
    "    def _cosine_similarity(self, emb1, emb2):\n",
    "        n1, n2 = np.linalg.norm(emb1), np.linalg.norm(emb2)\n",
    "        if n1 == 0 or n2 == 0:\n",
    "            return 0.0\n",
    "        return np.dot(emb1, emb2) / (n1 * n2)\n",
    "\n",
    "    def _jaccard_similarity(self, u: int, v: int) -> float:\n",
    "        \"\"\"Neighbor overlap — captures structural relatedness for gene symbols.\"\"\"\n",
    "        n_u = self.neighbor_cache.get(u, set())\n",
    "        n_v = self.neighbor_cache.get(v, set())\n",
    "        if not n_u and not n_v:\n",
    "            return 0.0\n",
    "        intersection = len(n_u & n_v)\n",
    "        union = len(n_u | n_v)\n",
    "        return intersection / union if union > 0 else 0.0\n",
    "\n",
    "    def _get_beta_for_edge(self, u: int, v: int) -> float:\n",
    "        \"\"\"Node-type-pair-specific beta.\"\"\"\n",
    "        u_type = self.graph.nodes[u].get('node_type', '')\n",
    "        v_type = self.graph.nodes[v].get('node_type', '')\n",
    "        pair = (u_type, v_type)\n",
    "        beta_map = {\n",
    "            ('drug', 'gene/protein'):           0.5,\n",
    "            ('gene/protein', 'gene/protein'):   0.4,\n",
    "            ('gene/protein', 'biological_process'): 0.5,\n",
    "            ('biological_process', 'gene/protein'): 0.5,\n",
    "            ('gene/protein', 'disease'):        0.4,\n",
    "            ('gene/protein', 'pathway'):        0.4,\n",
    "            ('pathway', 'gene/protein'):        0.4,\n",
    "        }\n",
    "        return beta_map.get(pair, self.beta * 0.5)\n",
    "\n",
    "    def compute_edge_weights(self) -> nx.DiGraph:\n",
    "        \"\"\"Compute edge weights: semantic sim × edge-type multiplier. All baked in.\"\"\"\n",
    "        if self.embeddings is None:\n",
    "            self.compute_embeddings()\n",
    "        print(\"  Computing v2 edge weights...\")\n",
    "        self.weighted_graph = self.graph.copy()\n",
    "\n",
    "        for u, v in self.weighted_graph.edges():\n",
    "            emb_u = self.embeddings.get(u)\n",
    "            emb_v = self.embeddings.get(v)\n",
    "\n",
    "            if emb_u is not None and emb_v is not None:\n",
    "                cos_sim = self._cosine_similarity(emb_u, emb_v)\n",
    "                jac_sim = self._jaccard_similarity(u, v)\n",
    "                combined_sim = 0.6 * max(0, cos_sim) + 0.4 * jac_sim\n",
    "            else:\n",
    "                combined_sim = 0.0\n",
    "\n",
    "            beta = self._get_beta_for_edge(u, v)\n",
    "            base_weight = 1.0 - beta * combined_sim\n",
    "\n",
    "            # Edge-type multiplier from GT frequency\n",
    "            edge_data = self.graph.get_edge_data(u, v) or {}\n",
    "            edge_rel = edge_data.get('relation', 'unknown')\n",
    "            type_mult = self.edge_type_weights.get(edge_rel, 1.5)\n",
    "\n",
    "            self.weighted_graph[u][v]['weight'] = max(0.01, base_weight * type_mult)\n",
    "\n",
    "        print(f\"  Edge weights computed for {self.weighted_graph.number_of_edges():,} edges\")\n",
    "        return self.weighted_graph\n",
    "\n",
    "    def find_path(self, source: int, target: int) -> Tuple[List[int], List[str], float]:\n",
    "        \"\"\"Standard Dijkstra on precomputed weights. Fast — no relation tracking in state.\"\"\"\n",
    "        if self.weighted_graph is None:\n",
    "            self.compute_edge_weights()\n",
    "        return find_path_engine(self.graph, self.weighted_graph, source, target, allowed_transition)\n",
    "\n",
    "\n",
    "print(\"✓ SemanticBridgingV2 loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Data & Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PrimeKG...\n",
      "  Nodes: 129,375, Edges: 8,100,498\n",
      "\n",
      "Loading ground truth...\n",
      "Loading fold assignments...\n",
      "\n",
      "  Pathways (>= 4 nodes): 150\n",
      "  Fold distribution:\n",
      "  {0: 32, 1: 31, 2: 30, 3: 29, 4: 28}\n",
      "\n",
      "Building graph...\n",
      "✓ Graph: 129,375 nodes, 8,099,284 edges\n",
      "  Hub threshold: 412\n"
     ]
    }
   ],
   "source": [
    "# Load PrimeKG\n",
    "print(\"Loading PrimeKG...\")\n",
    "nodes_df = pd.read_csv(PATHS['nodes'])\n",
    "edges_df = pd.read_csv(PATHS['edges'])\n",
    "print(f\"  Nodes: {len(nodes_df):,}, Edges: {len(edges_df):,}\")\n",
    "\n",
    "# Load ground truth\n",
    "print(\"\\nLoading ground truth...\")\n",
    "gt_nodes_df = pd.read_csv(PATHS['ground_truth_nodes'], dtype={'node_index': int})\n",
    "gt_edges_df = pd.read_csv(PATHS['ground_truth_edges'])\n",
    "\n",
    "# Load fold assignments\n",
    "print(\"Loading fold assignments...\")\n",
    "folds_df = pd.read_csv(PATHS['fold_assignments'])\n",
    "\n",
    "# Filter to >= MIN_PATHWAY_NODES\n",
    "pathway_sizes = gt_nodes_df.groupby('pathway_id').size()\n",
    "valid_pathways = pathway_sizes[pathway_sizes >= MIN_PATHWAY_NODES].index.tolist()\n",
    "\n",
    "gt_nodes_df = gt_nodes_df[gt_nodes_df['pathway_id'].isin(valid_pathways)].reset_index(drop=True)\n",
    "gt_edges_df = gt_edges_df[gt_edges_df['pathway_id'].isin(valid_pathways)].reset_index(drop=True)\n",
    "folds_df = folds_df[folds_df['pathway_id'].isin(valid_pathways)].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n  Pathways (>= {MIN_PATHWAY_NODES} nodes): {len(valid_pathways)}\")\n",
    "print(f\"  Fold distribution:\")\n",
    "print(f\"  {folds_df['fold'].value_counts().sort_index().to_dict()}\")\n",
    "\n",
    "# Build graph\n",
    "print(\"\\nBuilding graph...\")\n",
    "def build_graph(nodes_df, edges_df, bidirectional=True):\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in nodes_df.iterrows():\n",
    "        G.add_node(int(row['node_index']), node_id=str(row['node_id']),\n",
    "                    node_name=str(row['node_name']), node_type=str(row['node_type']))\n",
    "    for _, row in edges_df.iterrows():\n",
    "        src, dst = int(row['x_index']), int(row['y_index'])\n",
    "        rel, disp = str(row['relation']), str(row['display_relation'])\n",
    "        G.add_edge(src, dst, relation=rel, display_relation=disp)\n",
    "        if bidirectional:\n",
    "            G.add_edge(dst, src, relation=rel, display_relation=disp)\n",
    "    return G\n",
    "\n",
    "G = build_graph(nodes_df, edges_df, bidirectional=True)\n",
    "print(f\"✓ Graph: {G.number_of_nodes():,} nodes, {G.number_of_edges():,} edges\")\n",
    "\n",
    "# Precompute evaluation helpers\n",
    "degree_count = compute_degree_counts(edges_df)\n",
    "hub_threshold = compute_hub_threshold(degree_count, percentile=95)\n",
    "print(f\"  Hub threshold: {hub_threshold:.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Mine Meta-Path Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining meta-path patterns from ground truth...\n",
      "  Using edge type column: 'relation'\n",
      "  Mined 35 unique meta-path patterns\n",
      "  35 patterns with count >= 1\n",
      "  119 valid prefixes for search constraint\n",
      "\n",
      "  Top 15 patterns:\n",
      "     28x  drug_protein → drug_protein → indication\n",
      "     20x  drug_protein → bioprocess_protein → bioprocess_protein → disease_protein\n",
      "     16x  drug_protein → protein_protein → disease_protein\n",
      "     10x  drug_protein → protein_protein → protein_protein → bioprocess_protein → bioprocess_protein → bioprocess_protein → bioprocess_protein → disease_protein\n",
      "      8x  drug_protein → pathway_protein → pathway_protein → disease_protein\n",
      "      8x  drug_effect → drug_effect → indication\n",
      "      7x  drug_protein → molfunc_protein → molfunc_protein → protein_protein → disease_protein\n",
      "      6x  drug_protein → anatomy_protein_present → anatomy_protein_present → bioprocess_protein → bioprocess_protein → protein_protein → bioprocess_protein → bioprocess_protein → disease_protein\n",
      "      5x  drug_drug → drug_protein → disease_protein\n",
      "      4x  drug_protein → protein_protein → bioprocess_protein → bioprocess_protein → protein_protein → bioprocess_protein → bioprocess_protein → drug_protein → indication\n",
      "      3x  drug_protein → protein_protein → drug_protein → indication\n",
      "      3x  drug_protein → bioprocess_protein → bioprocess_protein → protein_protein → disease_protein\n",
      "      3x  drug_drug → drug_protein → protein_protein → protein_protein → bioprocess_protein → bioprocess_protein → bioprocess_protein → bioprocess_protein → disease_protein\n",
      "      2x  drug_protein → drug_protein → drug_protein → disease_protein\n",
      "      2x  drug_protein → bioprocess_protein → bioprocess_protein → bioprocess_protein → bioprocess_protein → disease_protein\n",
      "  Edge type weights (sample):\n",
      "    bioprocess_protein                 : 0.700\n",
      "    drug_protein                       : 0.700\n",
      "    disease_protein                    : 0.796\n",
      "    protein_protein                    : 0.798\n",
      "    indication                         : 0.903\n",
      "    drug_drug                          : 1.000\n",
      "    phenotype_protein                  : 1.000\n",
      "    pathway_protein                    : 1.000\n",
      "    bioprocess_bioprocess              : 1.000\n",
      "    drug_effect                        : 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Mining meta-path patterns from ground truth...\")\n",
    "patterns, pattern_counts, prefix_set = mine_metapath_patterns(gt_edges_df, gt_nodes_df, min_count=1)\n",
    "\n",
    "# Compute edge-type weights from GT frequency\n",
    "all_edge_types = set(edges_df['relation'].unique())\n",
    "edge_type_weights = compute_edge_type_weights(gt_edges_df, all_edge_types, bonus=0.3, penalty=2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Algorithm Runner & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Runner & evaluation loaded\n"
     ]
    }
   ],
   "source": [
    "def run_algorithm(algo_find_path_fn, graph, gt_nodes_df, algo_name, verbose=True):\n",
    "    \"\"\"Run algorithm on all pathways, return predictions DataFrame.\"\"\"\n",
    "    results = []\n",
    "    pathways = gt_nodes_df['pathway_id'].unique()\n",
    "    n_total = len(pathways)\n",
    "    for idx, pathway_id in enumerate(pathways):\n",
    "        pw = gt_nodes_df[gt_nodes_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        source_idx = int(pw.iloc[0]['node_index'])\n",
    "        target_idx = int(pw.iloc[-1]['node_index'])\n",
    "        if verbose and idx % 25 == 0:\n",
    "            print(f\"  [{idx+1}/{n_total}] ...\")\n",
    "        start_t = time.perf_counter()\n",
    "        try:\n",
    "            path, relations, cost = algo_find_path_fn(source_idx, target_idx)\n",
    "        except Exception as e:\n",
    "            path, relations, cost = [], [], float('inf')\n",
    "        elapsed_ms = (time.perf_counter() - start_t) * 1000\n",
    "        if path:\n",
    "            node_ids = [graph.nodes[n].get('node_id', str(n)) for n in path]\n",
    "            node_names = [graph.nodes[n].get('node_name', str(n)) for n in path]\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id, 'algorithm': algo_name,\n",
    "                'predicted_node_indices': ','.join(map(str, path)),\n",
    "                'predicted_node_ids': ','.join(node_ids),\n",
    "                'predicted_node_names': ','.join(node_names),\n",
    "                'predicted_relations': ','.join(relations),\n",
    "                'predicted_length': len(path), 'ground_truth_length': len(pw),\n",
    "                'time_ms': elapsed_ms,\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id, 'algorithm': algo_name,\n",
    "                'predicted_node_indices': 'NONE', 'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE', 'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0, 'ground_truth_length': len(pw),\n",
    "                'time_ms': elapsed_ms,\n",
    "            })\n",
    "    df = pd.DataFrame(results)\n",
    "    found = (df['predicted_length'] > 0).sum()\n",
    "    avg_ms = df['time_ms'].mean()\n",
    "    print(f\"  ✓ {algo_name}: {found}/{n_total} paths found, avg {avg_ms:.1f}ms/pathway\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def evaluate_predictions(pred_df, gt_nodes_df, gt_edges_df, degree_count, hub_threshold):\n",
    "    \"\"\"Evaluate predictions against ground truth.\"\"\"\n",
    "    edge_type_col = None\n",
    "    for c in ['relation_type', 'relation', 'edge_type']:\n",
    "        if c in gt_edges_df.columns:\n",
    "            edge_type_col = c\n",
    "            break\n",
    "    if edge_type_col is None:\n",
    "        edge_type_col = gt_edges_df.columns[0]\n",
    "\n",
    "    results = []\n",
    "    for _, pred_row in pred_df.iterrows():\n",
    "        pathway_id = pred_row['pathway_id']\n",
    "        gt_pw = gt_nodes_df[gt_nodes_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        gt_ed = gt_edges_df[gt_edges_df['pathway_id'] == pathway_id]\n",
    "        gt_node_ids = [str(x) for x in gt_pw['node_id'].tolist()]\n",
    "        gt_target_id = str(gt_pw.iloc[-1]['node_id'])\n",
    "        gt_edge_types = gt_ed[edge_type_col].tolist() if not gt_ed.empty else []\n",
    "\n",
    "        if pred_row['predicted_node_ids'] == 'NONE':\n",
    "            pred_node_ids, pred_indices, pred_relations = [], [], []\n",
    "        else:\n",
    "            pred_node_ids = pred_row['predicted_node_ids'].split(',')\n",
    "            pred_indices = [int(x) for x in pred_row['predicted_node_indices'].split(',')]\n",
    "            pred_relations = pred_row['predicted_relations'].split(',') if pred_row['predicted_relations'] != 'NONE' else []\n",
    "\n",
    "        results.append({\n",
    "            'pathway_id': pathway_id,\n",
    "            'algorithm': pred_row['algorithm'],\n",
    "            'precision': metric_precision(pred_node_ids, gt_node_ids),\n",
    "            'recall': metric_recall(pred_node_ids, gt_node_ids),\n",
    "            'f1_score': metric_f1(pred_node_ids, gt_node_ids),\n",
    "            'hits_at_1': calculate_hits_at_k(pred_node_ids, gt_target_id)['hits_at_1'],\n",
    "            'relation_type_accuracy': calculate_relation_accuracy(pred_relations, gt_edge_types),\n",
    "            'path_edit_distance': calculate_edit_distance(pred_node_ids, gt_node_ids),\n",
    "            'hub_node_ratio': calculate_hub_node_ratio(pred_indices, degree_count, hub_threshold),\n",
    "            'path_length_mae': calculate_path_length_mae(pred_row['predicted_length'], pred_row['ground_truth_length']),\n",
    "            'path_length_accuracy': metric_path_length_accuracy(pred_row['predicted_length'], pred_row['ground_truth_length']),\n",
    "            'mrr': metric_mrr(pred_node_ids, gt_node_ids),\n",
    "            'time_ms': pred_row['time_ms'],\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"✓ Runner & evaluation loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Run Semantic Bridging v2\n",
    "\n",
    "Semantic Bridging has no training phase, so no CV needed — just run with the new weights and meta-path penalties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SEMANTIC BRIDGING V2\n",
      "============================================================\n",
      "  Computing TF-IDF embeddings...\n",
      "  Building neighbor cache for co-occurrence features...\n",
      "  Embeddings: 129,375 nodes, dim=64\n",
      "  Computing v2 edge weights...\n",
      "  Edge weights computed for 8,099,284 edges\n",
      "  [1/150] ...\n",
      "  [26/150] ...\n",
      "  [51/150] ...\n",
      "  [76/150] ...\n",
      "  [101/150] ...\n",
      "  [126/150] ...\n",
      "  ✓ Semantic Bridging v2: 150/150 paths found, avg 5695.9ms/pathway\n",
      "\n",
      "Semantic Bridging v2 — Mean Metrics:\n",
      "precision                    0.7732\n",
      "recall                       0.4927\n",
      "f1_score                     0.5850\n",
      "relation_type_accuracy       0.7223\n",
      "path_edit_distance           0.5168\n",
      "hub_node_ratio               0.7408\n",
      "path_length_mae              2.5800\n",
      "time_ms                   5695.8652\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SEMANTIC BRIDGING V2\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sem_v2 = SemanticBridgingV2(G, beta=0.3, prefix_set=prefix_set,\n",
    "                             edge_type_weights=edge_type_weights, metapath_penalty=10.0)\n",
    "sem_v2.compute_embeddings()\n",
    "sem_v2.compute_edge_weights()\n",
    "\n",
    "sem_v2_preds = run_algorithm(sem_v2.find_path, G, gt_nodes_df, 'Semantic Bridging v2')\n",
    "sem_v2_eval = evaluate_predictions(sem_v2_preds, gt_nodes_df, gt_edges_df, degree_count, hub_threshold)\n",
    "\n",
    "print(\"\\nSemantic Bridging v2 — Mean Metrics:\")\n",
    "metric_cols = ['precision', 'recall', 'f1_score', 'relation_type_accuracy',\n",
    "               'path_edit_distance', 'hub_node_ratio', 'path_length_mae', 'time_ms']\n",
    "print(sem_v2_eval[metric_cols].mean().round(4).to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Run Learned A* v2 with 5-Fold Cross-Validation\n",
    "\n",
    "For each fold: train on 4 folds, evaluate on the held-out fold. Concatenate results for honest evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LEARNED A* V2 — 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "\n",
      "Pre-training embeddings (shared across folds)...\n",
      "  Computing spectral embeddings...\n",
      "  Embeddings: 129,375 nodes, dim=64\n",
      "\n",
      "==================================================\n",
      "FOLD 0: training on folds != 0, testing on fold 0\n",
      "==================================================\n",
      "  Train: 118 pathways, Test: 32 pathways\n",
      "  Training pathways (>= 4 nodes): 118\n",
      "  Training edge weight MLP (v2 features)...\n",
      "  MLP trained on 1382 samples (R²=0.906)\n",
      "  Feature dim: 35\n",
      "  [1/32] ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Evaluate on test fold\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     test_gt \u001b[38;5;241m=\u001b[39m gt_nodes_df[gt_nodes_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpathway_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(test_pws)]\n\u001b[0;32m---> 43\u001b[0m     fold_preds \u001b[38;5;241m=\u001b[39m \u001b[43mrun_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_gt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLearned A* v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     all_astar_preds\u001b[38;5;241m.\u001b[39mappend(fold_preds)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Concatenate all fold results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mrun_algorithm\u001b[0;34m(algo_find_path_fn, graph, gt_nodes_df, algo_name, verbose)\u001b[0m\n\u001b[1;32m     12\u001b[0m start_t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     path, relations, cost \u001b[38;5;241m=\u001b[39m \u001b[43malgo_find_path_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     16\u001b[0m     path, relations, cost \u001b[38;5;241m=\u001b[39m [], [], \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 186\u001b[0m, in \u001b[0;36mLearnedAStarV2.find_path\u001b[0;34m(self, source, target)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m     feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edge_features_v2(current, neighbor, hop_count\u001b[38;5;241m=\u001b[39mhop_count,\n\u001b[1;32m    185\u001b[0m                                 source\u001b[38;5;241m=\u001b[39msource, target\u001b[38;5;241m=\u001b[39mtarget)\n\u001b[0;32m--> 186\u001b[0m     feat_scaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     base_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp\u001b[38;5;241m.\u001b[39mpredict(feat_scaled)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m2.0\u001b[39m))\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:1062\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1059\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1061\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1062\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:2920\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \n\u001b[1;32m   2847\u001b[0m \u001b[38;5;124;03mThis helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;124;03m    validated.\u001b[39;00m\n\u001b[1;32m   2918\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2919\u001b[0m _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m-> 2920\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n\u001b[1;32m   2922\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2923\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2924\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2925\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/sklearn/utils/_tags.py:398\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag_provider \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# TODO(1.7): turn the warning into an error\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         tags \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(exc) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuper\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    401\u001b[0m             \u001b[38;5;66;03m# workaround the regression reported in\u001b[39;00m\n\u001b[1;32m    402\u001b[0m             \u001b[38;5;66;03m# https://github.com/scikit-learn/scikit-learn/issues/30479\u001b[39;00m\n\u001b[1;32m    403\u001b[0m             \u001b[38;5;66;03m# `__sklearn_tags__` is implemented by calling\u001b[39;00m\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;66;03m# `super().__sklearn_tags__()` but there is no `__sklearn_tags__`\u001b[39;00m\n\u001b[1;32m    405\u001b[0m             \u001b[38;5;66;03m# method in the base class.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:1134\u001b[0m, in \u001b[0;36mStandardScaler.__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m tags\u001b[38;5;241m.\u001b[39minput_tags\u001b[38;5;241m.\u001b[39mallow_nan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m tags\u001b[38;5;241m.\u001b[39minput_tags\u001b[38;5;241m.\u001b[39msparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean\n\u001b[0;32m-> 1134\u001b[0m \u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_tags\u001b[49m\u001b[38;5;241m.\u001b[39mpreserves_dtype \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tags\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LEARNED A* V2 — 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_astar_preds = []\n",
    "\n",
    "# Pre-train embeddings once (not pathway-dependent)\n",
    "print(\"\\nPre-training embeddings (shared across folds)...\")\n",
    "astar_base = LearnedAStarV2(G, embedding_dim=64, prefix_set=prefix_set,\n",
    "                              edge_type_weights=edge_type_weights)\n",
    "astar_base.train_embeddings()\n",
    "shared_embeddings = astar_base.embeddings\n",
    "\n",
    "for fold_id in range(N_FOLDS):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold_id}: training on folds != {fold_id}, testing on fold {fold_id}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Split pathways\n",
    "    test_pws = folds_df[folds_df['fold'] == fold_id]['pathway_id'].tolist()\n",
    "    train_pws = folds_df[folds_df['fold'] != fold_id]['pathway_id'].tolist()\n",
    "\n",
    "    print(f\"  Train: {len(train_pws)} pathways, Test: {len(test_pws)} pathways\")\n",
    "\n",
    "    # Prepare training data from train folds only\n",
    "    training_pathways = []\n",
    "    for pid in train_pws:\n",
    "        pw = gt_nodes_df[gt_nodes_df['pathway_id'] == pid].sort_values('step_order')\n",
    "        if len(pw) >= MIN_PATHWAY_NODES:\n",
    "            training_pathways.append({'path_nodes': pw['node_index'].tolist()})\n",
    "    print(f\"  Training pathways (>= {MIN_PATHWAY_NODES} nodes): {len(training_pathways)}\")\n",
    "\n",
    "    # Initialize fresh algorithm with shared embeddings\n",
    "    algo = LearnedAStarV2(G, embedding_dim=64, prefix_set=prefix_set,\n",
    "                           edge_type_weights=edge_type_weights)\n",
    "    algo.embeddings = shared_embeddings\n",
    "\n",
    "    # Train on train folds only\n",
    "    algo.train_edge_weights(training_pathways)\n",
    "\n",
    "    # Evaluate on test fold\n",
    "    test_gt = gt_nodes_df[gt_nodes_df['pathway_id'].isin(test_pws)]\n",
    "    fold_preds = run_algorithm(algo.find_path, G, test_gt, f'Learned A* v2')\n",
    "    all_astar_preds.append(fold_preds)\n",
    "\n",
    "# Concatenate all fold results\n",
    "astar_v2_preds = pd.concat(all_astar_preds, ignore_index=True)\n",
    "astar_v2_eval = evaluate_predictions(astar_v2_preds, gt_nodes_df, gt_edges_df, degree_count, hub_threshold)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"LEARNED A* V2 — AGGREGATE RESULTS ({len(astar_v2_preds)} pathways)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(astar_v2_eval[metric_cols].mean().round(4).to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Compare v1 vs v2\n",
    "\n",
    "Load v1 baseline results and compare side-by-side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine v2 results\n",
    "all_v2_eval = pd.concat([sem_v2_eval, astar_v2_eval], ignore_index=True)\n",
    "\n",
    "# Print comparison\n",
    "print(\"=\" * 80)\n",
    "print(\"V2 RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "v2_summary = all_v2_eval.groupby('algorithm')[metric_cols].mean().round(4)\n",
    "print(v2_summary.T.to_string())\n",
    "\n",
    "# If v1 results exist, compare\n",
    "v1_path = 'evaluation_results_all_algorithms.csv'\n",
    "if os.path.exists(v1_path):\n",
    "    print(f\"\\n\\n{'='*80}\")\n",
    "    print(\"V1 vs V2 COMPARISON\")\n",
    "    print(f\"{'='*80}\")\n",
    "    v1_eval = pd.read_csv(v1_path)\n",
    "\n",
    "    # Extract v1 results for the same algorithms\n",
    "    v1_sem = v1_eval[v1_eval['algorithm'] == 'Semantic Bridging'][metric_cols].mean()\n",
    "    v1_astar = v1_eval[v1_eval['algorithm'] == 'Learned A*'][metric_cols].mean()\n",
    "\n",
    "    v2_sem = sem_v2_eval[metric_cols].mean()\n",
    "    v2_astar = astar_v2_eval[metric_cols].mean()\n",
    "\n",
    "    print(f\"\\n{'Metric':<28s} {'Sem v1':>10s} {'Sem v2':>10s} {'Δ':>8s}    {'A* v1':>10s} {'A* v2':>10s} {'Δ':>8s}\")\n",
    "    print(f\"{'-'*88}\")\n",
    "    for m in metric_cols:\n",
    "        s1, s2 = v1_sem[m], v2_sem[m]\n",
    "        a1, a2 = v1_astar[m], v2_astar[m]\n",
    "        sd = s2 - s1\n",
    "        ad = a2 - a1\n",
    "        print(f\"{m:<28s} {s1:>10.4f} {s2:>10.4f} {sd:>+8.4f}    {a1:>10.4f} {a2:>10.4f} {ad:>+8.4f}\")\n",
    "else:\n",
    "    print(f\"\\n  (v1 results not found at '{v1_path}' — run baseline notebook first for comparison)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 by pathway length\n",
    "gt_len_map = gt_nodes_df.groupby('pathway_id').size().to_dict()\n",
    "all_v2_eval['gt_length'] = all_v2_eval['pathway_id'].map(gt_len_map)\n",
    "\n",
    "print(\"F1 by pathway length:\")\n",
    "pivot = all_v2_eval.pivot_table(index='gt_length', columns='algorithm', values='f1_score', aggfunc='mean').round(4)\n",
    "print(pivot.to_string())\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# F1 comparison\n",
    "ax = axes[0]\n",
    "for alg in all_v2_eval['algorithm'].unique():\n",
    "    sub = all_v2_eval[all_v2_eval['algorithm'] == alg]\n",
    "    by_len = sub.groupby('gt_length')['f1_score'].mean()\n",
    "    ax.plot(by_len.index, by_len.values, 'o-', label=alg)\n",
    "ax.set_xlabel('Ground Truth Path Length')\n",
    "ax.set_ylabel('Mean F1 Score')\n",
    "ax.set_title('F1 by Pathway Length (v2)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Relation accuracy comparison\n",
    "ax = axes[1]\n",
    "for alg in all_v2_eval['algorithm'].unique():\n",
    "    sub = all_v2_eval[all_v2_eval['algorithm'] == alg]\n",
    "    by_len = sub.groupby('gt_length')['relation_type_accuracy'].mean()\n",
    "    ax.plot(by_len.index, by_len.values, 'o-', label=alg)\n",
    "ax.set_xlabel('Ground Truth Path Length')\n",
    "ax.set_ylabel('Mean Relation Accuracy')\n",
    "ax.set_title('Relation Accuracy by Length (v2)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Overall bar comparison\n",
    "ax = axes[2]\n",
    "compare_metrics = ['f1_score', 'relation_type_accuracy', 'path_edit_distance', 'recall']\n",
    "x = np.arange(len(compare_metrics))\n",
    "width = 0.35\n",
    "algos = all_v2_eval['algorithm'].unique()\n",
    "colors = ['#9b59b6', '#f39c12']\n",
    "for i, alg in enumerate(algos):\n",
    "    vals = [all_v2_eval[all_v2_eval['algorithm'] == alg][m].mean() for m in compare_metrics]\n",
    "    ax.bar(x + i * width, vals, width, label=alg, color=colors[i % len(colors)])\n",
    "ax.set_xticks(x + width / 2)\n",
    "ax.set_xticklabels(['F1 ↑', 'Rel Acc ↑', 'Edit Dist ↓', 'Recall ↑'], fontsize=9)\n",
    "ax.set_title('V2 Algorithm Comparison')\n",
    "ax.legend(fontsize=8)\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('v2_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: v2_comparison.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save v2 results\n",
    "all_v2_eval.to_csv('v2_evaluation_results.csv', index=False)\n",
    "print(f\"✓ Saved: v2_evaluation_results.csv ({len(all_v2_eval)} rows)\")\n",
    "\n",
    "sem_v2_preds.to_csv('v2_predictions_semantic_bridging.csv', index=False)\n",
    "print(f\"✓ Saved: v2_predictions_semantic_bridging.csv\")\n",
    "\n",
    "astar_v2_preds.to_csv('v2_predictions_learned_astar.csv', index=False)\n",
    "print(f\"✓ Saved: v2_predictions_learned_astar.csv\")\n",
    "\n",
    "v2_summary.to_csv('v2_algorithm_summary.csv')\n",
    "print(f\"✓ Saved: v2_algorithm_summary.csv\")\n",
    "\n",
    "print(\"\\n✓ All v2 outputs saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
