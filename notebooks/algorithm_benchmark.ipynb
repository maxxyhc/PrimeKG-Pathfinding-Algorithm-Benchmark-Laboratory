{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Repurposing Pathfinding Algorithm Benchmark\n",
    "\n",
    "**Purpose:** Evaluate graph pathfinding algorithms for drug repurposing by comparing predicted mechanistic pathways against curated ground truth pathways.\n",
    "\n",
    "**What This Notebook Does:**\n",
    "1. Loads the PrimeKG knowledge graph and ground truth pathways\n",
    "2. Runs two baseline algorithms: Shortest Path and Meta-Path Constrained BFS\n",
    "3. Evaluates predictions using 9 metrics\n",
    "4. Visualizes results for comparison\n",
    "\n",
    "**Ground Truth Pathways:** 6 curated drug→disease mechanistic pathways (bupropion, minoxidil, sildenafil, thalidomide, finasteride×2)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import libraries and configure paths. Update the `DATA_DIR` variable to match your local setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import deque, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === CONFIGURE PATHS ===\n",
    "# Update this to your project root directory\n",
    "DATA_DIR = '/Users/johncollins/Desktop/PrimeKG-Pathfinding-Algorithm-Benchmark-Laboratory'\n",
    "\n",
    "# File paths (relative to DATA_DIR)\n",
    "PATHS = {\n",
    "    'nodes': f'{DATA_DIR}/data/processed/nodes_cleaned.csv',\n",
    "    'edges': f'{DATA_DIR}/data/processed/edges_cleaned.csv',\n",
    "    'ground_truth_nodes': f'{DATA_DIR}/johns_cleaned_ground_truths/ground_truth_final.csv',\n",
    "    'ground_truth_edges': f'{DATA_DIR}/johns_cleaned_ground_truths/pathway_edges_final.csv'\n",
    "}\n",
    "\n",
    "print(\"Configuration complete. Paths set to:\")\n",
    "for name, path in PATHS.items():\n",
    "    print(f\"  {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load Data\n",
    "\n",
    "Load the PrimeKG knowledge graph and ground truth pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PrimeKG data\n",
    "print(\"Loading PrimeKG data...\")\n",
    "nodes = pd.read_csv(PATHS['nodes'])\n",
    "edges = pd.read_csv(PATHS['edges'])\n",
    "\n",
    "print(f\"  Nodes: {len(nodes):,}\")\n",
    "print(f\"  Edges: {len(edges):,}\")\n",
    "print(f\"  Node types: {nodes[':LABEL'].nunique()}\")\n",
    "print(f\"  Edge types: {edges[':TYPE'].nunique()}\")\n",
    "\n",
    "# Load ground truth\n",
    "print(\"\\nLoading ground truth pathways...\")\n",
    "ground_truth_nodes = pd.read_csv(PATHS['ground_truth_nodes'], dtype={'node_index': int})\n",
    "ground_truth_edges = pd.read_csv(PATHS['ground_truth_edges'])\n",
    "\n",
    "pathways = ground_truth_nodes['pathway_id'].unique()\n",
    "print(f\"  Pathways: {len(pathways)}\")\n",
    "for p in pathways:\n",
    "    n_nodes = len(ground_truth_nodes[ground_truth_nodes['pathway_id'] == p])\n",
    "    print(f\"    - {p}: {n_nodes} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Build Knowledge Graph\n",
    "\n",
    "Construct a NetworkX directed graph with node/edge attributes for pathfinding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(nodes_df, edges_df, bidirectional=True):\n",
    "    \"\"\"\n",
    "    Build a NetworkX graph from PrimeKG data.\n",
    "    \n",
    "    Args:\n",
    "        nodes_df: DataFrame with columns [node_index:ID, node_id, node_name, :LABEL]\n",
    "        edges_df: DataFrame with columns [:START_ID, :END_ID, :TYPE, display_relation]\n",
    "        bidirectional: If True, add edges in both directions\n",
    "    \n",
    "    Returns:\n",
    "        NetworkX DiGraph\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for _, row in nodes_df.iterrows():\n",
    "        G.add_node(\n",
    "            int(row['node_index:ID']),\n",
    "            node_id=str(row['node_id']),\n",
    "            node_name=str(row['node_name']),\n",
    "            node_type=str(row[':LABEL'])\n",
    "        )\n",
    "    \n",
    "    # Add edges\n",
    "    for _, row in edges_df.iterrows():\n",
    "        G.add_edge(\n",
    "            int(row[':START_ID']), \n",
    "            int(row[':END_ID']),\n",
    "            relation=str(row[':TYPE']),\n",
    "            display_relation=str(row['display_relation'])\n",
    "        )\n",
    "        if bidirectional:\n",
    "            G.add_edge(\n",
    "                int(row[':END_ID']), \n",
    "                int(row[':START_ID']),\n",
    "                relation=str(row[':TYPE']),\n",
    "                display_relation=str(row['display_relation'])\n",
    "            )\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Build the graph\n",
    "print(\"Building graph...\")\n",
    "G = build_graph(nodes, edges, bidirectional=True)\n",
    "print(f\"Graph built: {G.number_of_nodes():,} nodes, {G.number_of_edges():,} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Define Evaluation Metrics\n",
    "\n",
    "We evaluate algorithms using 9 metrics across three categories:\n",
    "\n",
    "| Category | Metrics | What It Measures |\n",
    "|----------|---------|------------------|\n",
    "| **Node Accuracy** | Precision, Recall, F1 | Are the right nodes in the path? |\n",
    "| **Target Finding** | Hits@1, Hits@3, Hits@5 | Does the path reach the disease? |\n",
    "| **Mechanistic Quality** | Relation Accuracy, Edit Distance, Hub Ratio | Is the path biologically valid? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EVALUATION FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def calculate_precision_recall_f1(predicted_ids, ground_truth_ids):\n",
    "    \"\"\"\n",
    "    Calculate node overlap metrics.\n",
    "    \n",
    "    Precision: What fraction of predicted nodes are correct?\n",
    "    Recall: What fraction of ground truth nodes were found?\n",
    "    \"\"\"\n",
    "    if not predicted_ids or predicted_ids == ['NONE']:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    pred_set = set(predicted_ids)\n",
    "    gt_set = set(ground_truth_ids)\n",
    "    \n",
    "    intersection = len(pred_set & gt_set)\n",
    "    precision = intersection / len(pred_set) if pred_set else 0\n",
    "    recall = intersection / len(gt_set) if gt_set else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def calculate_hits_at_k(predicted_ids, ground_truth_target, k_values=[1, 3, 5]):\n",
    "    \"\"\"\n",
    "    Check if the target disease appears in the first k nodes.\n",
    "    \n",
    "    For drug repurposing, we typically want the disease at the END of the path.\n",
    "    \"\"\"\n",
    "    hits = {f'hits_at_{k}': 0 for k in k_values}\n",
    "    \n",
    "    if not predicted_ids or predicted_ids == ['NONE']:\n",
    "        return hits\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Check last k nodes (path goes drug → ... → disease)\n",
    "        last_k = predicted_ids[-k:] if len(predicted_ids) >= k else predicted_ids\n",
    "        hits[f'hits_at_{k}'] = 1 if ground_truth_target in last_k else 0\n",
    "    \n",
    "    return hits\n",
    "\n",
    "\n",
    "def calculate_path_length_mae(predicted_length, ground_truth_length):\n",
    "    \"\"\"Mean Absolute Error in path length.\"\"\"\n",
    "    return abs(predicted_length - ground_truth_length)\n",
    "\n",
    "\n",
    "def calculate_relation_accuracy(predicted_relations, ground_truth_edge_types):\n",
    "    \"\"\"\n",
    "    What percentage of predicted edges use correct relation types?\n",
    "    \n",
    "    This measures whether the algorithm follows biologically valid edge sequences.\n",
    "    \"\"\"\n",
    "    if not predicted_relations:\n",
    "        return 0.0\n",
    "    \n",
    "    gt_types = set(ground_truth_edge_types)\n",
    "    matches = sum(1 for r in predicted_relations if r in gt_types)\n",
    "    \n",
    "    return matches / len(predicted_relations)\n",
    "\n",
    "\n",
    "def calculate_hub_node_ratio(predicted_indices, edges_df, percentile=95):\n",
    "    \"\"\"\n",
    "    What fraction of predicted nodes are \"hubs\" (highly connected)?\n",
    "    \n",
    "    High hub ratio may indicate the algorithm is taking shortcuts through\n",
    "    highly connected nodes rather than following specific mechanisms.\n",
    "    \"\"\"\n",
    "    # Calculate node degrees\n",
    "    degree_count = Counter()\n",
    "    for _, row in edges_df.iterrows():\n",
    "        degree_count[row[':START_ID']] += 1\n",
    "        degree_count[row[':END_ID']] += 1\n",
    "    \n",
    "    # Determine hub threshold\n",
    "    all_degrees = list(degree_count.values())\n",
    "    hub_threshold = np.percentile(all_degrees, percentile)\n",
    "    \n",
    "    # Count hubs in prediction\n",
    "    hub_count = sum(1 for idx in predicted_indices if degree_count.get(idx, 0) >= hub_threshold)\n",
    "    \n",
    "    return hub_count / len(predicted_indices) if predicted_indices else 0\n",
    "\n",
    "\n",
    "def calculate_edit_distance(predicted_ids, ground_truth_ids):\n",
    "    \"\"\"\n",
    "    Normalized Levenshtein edit distance between predicted and ground truth paths.\n",
    "    \n",
    "    Returns value in [0, 1] where 0 = identical, 1 = completely different.\n",
    "    \"\"\"\n",
    "    if not predicted_ids or predicted_ids == ['NONE']:\n",
    "        return 1.0\n",
    "    \n",
    "    # Dynamic programming for edit distance\n",
    "    m, n = len(predicted_ids), len(ground_truth_ids)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "    \n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if predicted_ids[i-1] == ground_truth_ids[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n",
    "    \n",
    "    # Normalize by max possible distance\n",
    "    return dp[m][n] / max(m, n)\n",
    "\n",
    "\n",
    "print(\"Evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Algorithm 1 - Shortest Path Baseline\n",
    "\n",
    "The simplest baseline: find the shortest path (by hop count) between drug and disease.\n",
    "\n",
    "**Expected behavior:**\n",
    "- ✅ Will always find the target disease (if connected)\n",
    "- ❌ May take shortcuts through direct drug→disease edges\n",
    "- ❌ Ignores edge types and biological mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_shortest_path(graph, ground_truth_df):\n",
    "    \"\"\"\n",
    "    Run shortest path algorithm on all pathways.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions for each pathway\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        \n",
    "        # Get source (drug) and target (disease) indices\n",
    "        source_idx = int(pathway_df.iloc[0]['node_index'])\n",
    "        target_idx = int(pathway_df.iloc[-1]['node_index'])\n",
    "        \n",
    "        source_name = pathway_df.iloc[0]['node_name']\n",
    "        target_name = pathway_df.iloc[-1]['node_name']\n",
    "        \n",
    "        print(f\"\\n{pathway_id}: {source_name} → {target_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Find shortest path\n",
    "            predicted_path = nx.shortest_path(graph, source_idx, target_idx)\n",
    "            predicted_node_ids = [graph.nodes[idx]['node_id'] for idx in predicted_path]\n",
    "            predicted_node_names = [graph.nodes[idx]['node_name'] for idx in predicted_path]\n",
    "            \n",
    "            # Get edge relations along path\n",
    "            predicted_relations = []\n",
    "            for i in range(len(predicted_path) - 1):\n",
    "                edge_data = graph.get_edge_data(predicted_path[i], predicted_path[i+1])\n",
    "                predicted_relations.append(edge_data['relation'])\n",
    "            \n",
    "            print(f\"  ✓ Found path: {len(predicted_path)} nodes\")\n",
    "            print(f\"  Path: {' → '.join(predicted_node_names[:5])}{'...' if len(predicted_path) > 5 else ''}\")\n",
    "            \n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': ','.join(map(str, predicted_path)),\n",
    "                'predicted_node_ids': ','.join(predicted_node_ids),\n",
    "                'predicted_node_names': ','.join(predicted_node_names),\n",
    "                'predicted_relations': ','.join(predicted_relations),\n",
    "                'predicted_length': len(predicted_path),\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "            \n",
    "        except nx.NetworkXNoPath:\n",
    "            print(f\"  ✗ No path found\")\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': 'NONE',\n",
    "                'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE',\n",
    "                'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0,\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run shortest path\n",
    "print(\"=\"*60)\n",
    "print(\"Running Shortest Path Algorithm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sp_predictions = run_shortest_path(G, ground_truth_nodes)\n",
    "sp_predictions.to_csv('baseline_shortest_path_predictions.csv', index=False)\n",
    "print(\"\\n✓ Saved: baseline_shortest_path_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Algorithm 2 - Meta-Path Constrained BFS\n",
    "\n",
    "An improved baseline that enforces biologically valid edge type sequences.\n",
    "\n",
    "**Valid meta-path patterns:**\n",
    "1. `drug → protein → disease` (direct mechanism)\n",
    "2. `drug → protein → protein → disease` (protein interactions)\n",
    "3. `drug → protein → anatomy → protein → disease` (tissue-specific)\n",
    "\n",
    "**Invalid shortcuts blocked:**\n",
    "- ❌ `drug → disease` (clinical indication, not mechanism)\n",
    "- ❌ `drug → drug → disease` (drug similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid meta-path patterns (edge type sequences)\n",
    "VALID_METAPATHS = [\n",
    "    # Pattern 1: Direct protein mechanism (drug → protein → disease)\n",
    "    ['drug_protein', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 2: Protein-protein interaction\n",
    "    ['drug_protein', 'protein_protein', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 3: Multiple protein interactions\n",
    "    ['drug_protein', 'protein_protein', 'protein_protein', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 4: Pathway-mediated\n",
    "    ['drug_protein', 'pathway_protein', 'disease_protein'],\n",
    "    ['drug_protein', 'pathway_protein', 'pathway_protein', 'disease_protein'],\n",
    "    ['drug_protein', 'pathway_protein', 'pathway_pathway', 'pathway_protein', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 5: Anatomy-mediated (tissue-specific)\n",
    "    ['drug_protein', 'anatomy_protein_present', 'anatomy_protein_present', 'disease_protein'],\n",
    "    \n",
    "    # Pattern 6: Complex pathways\n",
    "    ['drug_protein', 'protein_protein', 'pathway_protein', 'disease_protein'],\n",
    "    ['drug_protein', 'pathway_protein', 'pathway_protein', 'pathway_protein', 'disease_protein'],\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(VALID_METAPATHS)} valid meta-path patterns:\")\n",
    "for i, pattern in enumerate(VALID_METAPATHS, 1):\n",
    "    print(f\"  {i}. {' → '.join(pattern)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_metapath(relations, valid_metapaths):\n",
    "    \"\"\"Check if a relation sequence matches any valid meta-path pattern.\"\"\"\n",
    "    return relations in valid_metapaths\n",
    "\n",
    "\n",
    "def could_match_metapath(relations, valid_metapaths):\n",
    "    \"\"\"Check if the current relation sequence could potentially lead to a valid path.\"\"\"\n",
    "    for pattern in valid_metapaths:\n",
    "        if len(relations) <= len(pattern):\n",
    "            if relations == pattern[:len(relations)]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def metapath_constrained_bfs(source_idx, target_idx, graph, valid_metapaths, max_length=10):\n",
    "    \"\"\"\n",
    "    Find shortest path that follows valid meta-path patterns.\n",
    "    \n",
    "    Uses BFS but only explores edges that could lead to a valid meta-path.\n",
    "    \n",
    "    Returns:\n",
    "        (path_nodes, path_relations) or ([], []) if no valid path found\n",
    "    \"\"\"\n",
    "    # Queue: (current_node, path_so_far, relations_so_far)\n",
    "    queue = deque([(source_idx, [source_idx], [])])\n",
    "    visited = {source_idx: []}  # Track visited states with relation sequences\n",
    "    \n",
    "    while queue:\n",
    "        current_node, path, relations = queue.popleft()\n",
    "        \n",
    "        # Check if we reached target with valid meta-path\n",
    "        if current_node == target_idx:\n",
    "            if is_valid_metapath(relations, valid_metapaths):\n",
    "                return path, relations\n",
    "        \n",
    "        # Stop if path too long\n",
    "        if len(path) >= max_length:\n",
    "            continue\n",
    "        \n",
    "        # Explore neighbors\n",
    "        for neighbor in graph.neighbors(current_node):\n",
    "            edge_data = graph.get_edge_data(current_node, neighbor)\n",
    "            new_relation = edge_data['relation']\n",
    "            new_relations = relations + [new_relation]\n",
    "            \n",
    "            # Only continue if this could lead to a valid meta-path\n",
    "            if could_match_metapath(new_relations, valid_metapaths):\n",
    "                state_key = (neighbor, tuple(new_relations))\n",
    "                \n",
    "                # Avoid revisiting same state\n",
    "                if neighbor not in visited or visited[neighbor] != new_relations:\n",
    "                    visited[neighbor] = new_relations\n",
    "                    queue.append((neighbor, path + [neighbor], new_relations))\n",
    "    \n",
    "    return [], []  # No valid path found\n",
    "\n",
    "\n",
    "def run_metapath_algorithm(graph, ground_truth_df, valid_metapaths):\n",
    "    \"\"\"\n",
    "    Run meta-path constrained BFS on all pathways.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for pathway_id in ground_truth_df['pathway_id'].unique():\n",
    "        pathway_df = ground_truth_df[ground_truth_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        \n",
    "        source_idx = int(pathway_df.iloc[0]['node_index'])\n",
    "        target_idx = int(pathway_df.iloc[-1]['node_index'])\n",
    "        \n",
    "        source_name = pathway_df.iloc[0]['node_name']\n",
    "        target_name = pathway_df.iloc[-1]['node_name']\n",
    "        \n",
    "        gt_path = ' → '.join(pathway_df['node_name'].tolist())\n",
    "        \n",
    "        print(f\"\\n{pathway_id}: {source_name} → {target_name}\")\n",
    "        \n",
    "        # Find meta-path constrained path\n",
    "        predicted_path, predicted_relations = metapath_constrained_bfs(\n",
    "            source_idx, target_idx, graph, valid_metapaths\n",
    "        )\n",
    "        \n",
    "        if predicted_path:\n",
    "            predicted_node_ids = [graph.nodes[idx]['node_id'] for idx in predicted_path]\n",
    "            predicted_node_names = [graph.nodes[idx]['node_name'] for idx in predicted_path]\n",
    "            \n",
    "            print(f\"  ✓ Found valid path: {len(predicted_path)} nodes\")\n",
    "            print(f\"  Meta-path: {' → '.join(predicted_relations)}\")\n",
    "            print(f\"  Path: {' → '.join(predicted_node_names)}\")\n",
    "            print(f\"  Ground truth: {gt_path}\")\n",
    "            \n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': ','.join(map(str, predicted_path)),\n",
    "                'predicted_node_ids': ','.join(predicted_node_ids),\n",
    "                'predicted_node_names': ','.join(predicted_node_names),\n",
    "                'predicted_relations': ','.join(predicted_relations),\n",
    "                'predicted_length': len(predicted_path),\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  ✗ No valid meta-path found\")\n",
    "            results.append({\n",
    "                'pathway_id': pathway_id,\n",
    "                'predicted_node_indices': 'NONE',\n",
    "                'predicted_node_ids': 'NONE',\n",
    "                'predicted_node_names': 'NONE',\n",
    "                'predicted_relations': 'NONE',\n",
    "                'predicted_length': 0,\n",
    "                'ground_truth_length': len(pathway_df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run meta-path algorithm\n",
    "print(\"=\"*60)\n",
    "print(\"Running Meta-Path Constrained Algorithm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mp_predictions = run_metapath_algorithm(G, ground_truth_nodes, VALID_METAPATHS)\n",
    "mp_predictions.to_csv('baseline_metapath_predictions.csv', index=False)\n",
    "print(\"\\n✓ Saved: baseline_metapath_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Evaluate Both Algorithms\n",
    "\n",
    "Calculate all 9 metrics for both algorithms and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(predictions_df, ground_truth_nodes_df, ground_truth_edges_df, edges_df, algorithm_name):\n",
    "    \"\"\"\n",
    "    Calculate all 9 evaluation metrics for predictions.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with metrics for each pathway\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, pred_row in predictions_df.iterrows():\n",
    "        pathway_id = pred_row['pathway_id']\n",
    "        \n",
    "        # Get ground truth for this pathway\n",
    "        gt_nodes = ground_truth_nodes_df[ground_truth_nodes_df['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "        gt_edges = ground_truth_edges_df[ground_truth_edges_df['pathway_id'] == pathway_id]\n",
    "        \n",
    "        gt_node_ids = gt_nodes['node_id'].tolist()\n",
    "        gt_target_id = str(gt_nodes.iloc[-1]['node_id'])\n",
    "        gt_edge_types = gt_edges['relation_type'].tolist() if not gt_edges.empty else []\n",
    "        \n",
    "        # Parse predictions\n",
    "        if pred_row['predicted_node_ids'] == 'NONE':\n",
    "            pred_node_ids = []\n",
    "            pred_node_indices = []\n",
    "            pred_relations = []\n",
    "        else:\n",
    "            pred_node_ids = pred_row['predicted_node_ids'].split(',')\n",
    "            pred_node_indices = [int(x) for x in pred_row['predicted_node_indices'].split(',')]\n",
    "            pred_relations = pred_row['predicted_relations'].split(',') if pred_row['predicted_relations'] != 'NONE' else []\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision, recall, f1 = calculate_precision_recall_f1(pred_node_ids, [str(x) for x in gt_node_ids])\n",
    "        hits = calculate_hits_at_k(pred_node_ids, gt_target_id)\n",
    "        path_mae = calculate_path_length_mae(pred_row['predicted_length'], pred_row['ground_truth_length'])\n",
    "        relation_acc = calculate_relation_accuracy(pred_relations, gt_edge_types)\n",
    "        hub_ratio = calculate_hub_node_ratio(pred_node_indices, edges_df)\n",
    "        edit_dist = calculate_edit_distance(pred_node_ids, [str(x) for x in gt_node_ids])\n",
    "        \n",
    "        results.append({\n",
    "            'pathway_id': pathway_id,\n",
    "            'algorithm': algorithm_name,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'hits_at_1': hits['hits_at_1'],\n",
    "            'hits_at_3': hits['hits_at_3'],\n",
    "            'hits_at_5': hits['hits_at_5'],\n",
    "            'path_length_mae': path_mae,\n",
    "            'relation_type_accuracy': relation_acc,\n",
    "            'hub_node_ratio': hub_ratio,\n",
    "            'path_edit_distance': edit_dist\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Evaluate both algorithms\n",
    "print(\"Evaluating Shortest Path...\")\n",
    "sp_eval = evaluate_predictions(sp_predictions, ground_truth_nodes, ground_truth_edges, edges, 'Shortest Path')\n",
    "\n",
    "print(\"Evaluating Meta-Path...\")\n",
    "mp_eval = evaluate_predictions(mp_predictions, ground_truth_nodes, ground_truth_edges, edges, 'Meta-Path')\n",
    "\n",
    "# Combine results\n",
    "all_eval = pd.concat([sp_eval, mp_eval], ignore_index=True)\n",
    "all_eval.to_csv('evaluation_results_all.csv', index=False)\n",
    "print(\"\\n✓ Saved: evaluation_results_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Results Summary\n",
    "\n",
    "Compare algorithm performance across all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics per algorithm\n",
    "metrics = ['precision', 'recall', 'f1_score', 'hits_at_1', 'relation_type_accuracy', \n",
    "           'hub_node_ratio', 'path_edit_distance', 'path_length_mae']\n",
    "\n",
    "summary = all_eval.groupby('algorithm')[metrics].mean().round(3)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ALGORITHM COMPARISON: Average Metrics Across All Pathways\")\n",
    "print(\"=\"*70)\n",
    "print(summary.T.to_string())\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Count perfect matches\n",
    "print(\"\\nPerfect Matches (Edit Distance = 0):\")\n",
    "for alg in ['Shortest Path', 'Meta-Path']:\n",
    "    perfect = (all_eval[all_eval['algorithm'] == alg]['path_edit_distance'] == 0).sum()\n",
    "    total = len(all_eval[all_eval['algorithm'] == alg])\n",
    "    print(f\"  {alg}: {perfect}/{total} pathways\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Visualization\n",
    "\n",
    "Create comparison charts for the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure with 2x2 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Algorithm Comparison: Shortest Path vs Meta-Path', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Color scheme\n",
    "colors = {'Shortest Path': '#e74c3c', 'Meta-Path': '#3498db'}\n",
    "\n",
    "# --- Subplot 1: Node Accuracy Metrics ---\n",
    "ax1 = axes[0, 0]\n",
    "node_metrics = ['precision', 'recall', 'f1_score']\n",
    "x = np.arange(len(node_metrics))\n",
    "width = 0.35\n",
    "\n",
    "sp_vals = [summary.loc['Shortest Path', m] for m in node_metrics]\n",
    "mp_vals = [summary.loc['Meta-Path', m] for m in node_metrics]\n",
    "\n",
    "ax1.bar(x - width/2, sp_vals, width, label='Shortest Path', color=colors['Shortest Path'])\n",
    "ax1.bar(x + width/2, mp_vals, width, label='Meta-Path', color=colors['Meta-Path'])\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Node Accuracy Metrics')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(['Precision', 'Recall', 'F1 Score'])\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1.1)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# --- Subplot 2: Mechanistic Quality ---\n",
    "ax2 = axes[0, 1]\n",
    "mech_metrics = ['relation_type_accuracy', 'hub_node_ratio']\n",
    "x = np.arange(len(mech_metrics))\n",
    "\n",
    "sp_vals = [summary.loc['Shortest Path', m] for m in mech_metrics]\n",
    "mp_vals = [summary.loc['Meta-Path', m] for m in mech_metrics]\n",
    "\n",
    "ax2.bar(x - width/2, sp_vals, width, label='Shortest Path', color=colors['Shortest Path'])\n",
    "ax2.bar(x + width/2, mp_vals, width, label='Meta-Path', color=colors['Meta-Path'])\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('Mechanistic Quality Metrics')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(['Relation Accuracy', 'Hub Node Ratio'])\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Baseline')\n",
    "\n",
    "# --- Subplot 3: Path Length Comparison ---\n",
    "ax3 = axes[1, 0]\n",
    "pathways = sp_predictions['pathway_id'].tolist()\n",
    "x = np.arange(len(pathways))\n",
    "width = 0.25\n",
    "\n",
    "gt_lengths = sp_predictions['ground_truth_length'].tolist()\n",
    "sp_lengths = sp_predictions['predicted_length'].tolist()\n",
    "mp_lengths = mp_predictions['predicted_length'].tolist()\n",
    "\n",
    "ax3.bar(x - width, gt_lengths, width, label='Ground Truth', color='#2ecc71')\n",
    "ax3.bar(x, sp_lengths, width, label='Shortest Path', color=colors['Shortest Path'])\n",
    "ax3.bar(x + width, mp_lengths, width, label='Meta-Path', color=colors['Meta-Path'])\n",
    "ax3.set_ylabel('Path Length (nodes)')\n",
    "ax3.set_title('Path Length by Pathway')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(pathways, rotation=45, ha='right')\n",
    "ax3.legend()\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# --- Subplot 4: Radar Chart ---\n",
    "ax4 = axes[1, 1]\n",
    "ax4.set_visible(False)  # We'll create a polar plot instead\n",
    "\n",
    "# Create radar chart in new axis\n",
    "ax4_radar = fig.add_subplot(2, 2, 4, projection='polar')\n",
    "\n",
    "radar_metrics = ['precision', 'recall', 'f1_score', 'hits_at_1', 'relation_type_accuracy']\n",
    "radar_labels = ['Precision', 'Recall', 'F1', 'Hits@1', 'Relation Acc']\n",
    "\n",
    "# Get values and close the polygon\n",
    "sp_radar = [summary.loc['Shortest Path', m] for m in radar_metrics] + [summary.loc['Shortest Path', radar_metrics[0]]]\n",
    "mp_radar = [summary.loc['Meta-Path', m] for m in radar_metrics] + [summary.loc['Meta-Path', radar_metrics[0]]]\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, len(radar_metrics), endpoint=False).tolist()\n",
    "angles += angles[:1]  # Close the polygon\n",
    "\n",
    "ax4_radar.plot(angles, sp_radar, 'o-', linewidth=2, label='Shortest Path', color=colors['Shortest Path'])\n",
    "ax4_radar.fill(angles, sp_radar, alpha=0.25, color=colors['Shortest Path'])\n",
    "ax4_radar.plot(angles, mp_radar, 'o-', linewidth=2, label='Meta-Path', color=colors['Meta-Path'])\n",
    "ax4_radar.fill(angles, mp_radar, alpha=0.25, color=colors['Meta-Path'])\n",
    "\n",
    "ax4_radar.set_xticks(angles[:-1])\n",
    "ax4_radar.set_xticklabels(radar_labels)\n",
    "ax4_radar.set_ylim(0, 1)\n",
    "ax4_radar.set_title('Performance Profile', pad=20)\n",
    "ax4_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('algorithm_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: algorithm_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Detailed Pathway Analysis\n",
    "\n",
    "Look at individual pathway results to understand where each algorithm succeeds or fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DETAILED PATHWAY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for pathway_id in sp_predictions['pathway_id'].unique():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Pathway: {pathway_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Ground truth\n",
    "    gt = ground_truth_nodes[ground_truth_nodes['pathway_id'] == pathway_id].sort_values('step_order')\n",
    "    gt_path = ' → '.join(gt['node_name'].tolist())\n",
    "    print(f\"\\nGround Truth ({len(gt)} nodes):\")\n",
    "    print(f\"  {gt_path}\")\n",
    "    \n",
    "    # Shortest path prediction\n",
    "    sp = sp_predictions[sp_predictions['pathway_id'] == pathway_id].iloc[0]\n",
    "    sp_path = sp['predicted_node_names'].replace(',', ' → ')\n",
    "    print(f\"\\nShortest Path ({sp['predicted_length']} nodes):\")\n",
    "    print(f\"  {sp_path}\")\n",
    "    \n",
    "    # Meta-path prediction  \n",
    "    mp = mp_predictions[mp_predictions['pathway_id'] == pathway_id].iloc[0]\n",
    "    mp_path = mp['predicted_node_names'].replace(',', ' → ')\n",
    "    print(f\"\\nMeta-Path ({mp['predicted_length']} nodes):\")\n",
    "    print(f\"  {mp_path}\")\n",
    "    \n",
    "    # Metrics comparison\n",
    "    sp_metrics = all_eval[(all_eval['pathway_id'] == pathway_id) & (all_eval['algorithm'] == 'Shortest Path')].iloc[0]\n",
    "    mp_metrics = all_eval[(all_eval['pathway_id'] == pathway_id) & (all_eval['algorithm'] == 'Meta-Path')].iloc[0]\n",
    "    \n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"  {'Metric':<25} {'Shortest Path':>15} {'Meta-Path':>15}\")\n",
    "    print(f\"  {'-'*55}\")\n",
    "    for metric in ['f1_score', 'relation_type_accuracy', 'path_edit_distance']:\n",
    "        print(f\"  {metric:<25} {sp_metrics[metric]:>15.3f} {mp_metrics[metric]:>15.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Findings Summary\n",
    "\n",
    "### Shortest Path\n",
    "- ✅ **Strength:** Always finds the target disease (Hits@1 = 100%)\n",
    "- ❌ **Weakness:** Takes shortcuts through direct drug→disease edges (Relation Accuracy ≈ 17%)\n",
    "- ❌ **Weakness:** Paths too short (missing mechanistic intermediates)\n",
    "\n",
    "### Meta-Path Constrained BFS\n",
    "- ✅ **Strength:** Enforces biologically valid edge sequences (higher relation accuracy)\n",
    "- ✅ **Strength:** More perfect matches when mechanism is simple\n",
    "- ⚠️ **Limitation:** BFS finds first valid path, not necessarily the primary mechanism\n",
    "- ⚠️ **Limitation:** May find alternative proteins that satisfy the pattern\n",
    "\n",
    "### Next Steps for Algorithm Development\n",
    "1. **Edge weighting:** Prioritize primary drug targets over secondary interactions\n",
    "2. **Path ranking:** Use multiple features to rank paths beyond just length\n",
    "3. **Protein importance:** Incorporate drug-target binding affinity or expression data\n",
    "4. **Ensemble methods:** Combine multiple pathfinding strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Notebook complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - baseline_shortest_path_predictions.csv\")\n",
    "print(\"  - baseline_metapath_predictions.csv\")\n",
    "print(\"  - evaluation_results_all.csv\")\n",
    "print(\"  - algorithm_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
